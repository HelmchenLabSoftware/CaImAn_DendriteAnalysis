{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Temporary notebook for tuning of CNMF source extraction parameters\n",
    "In this notebook, a single-plane MMAP file is specified as input. The MMAP file should be concatenated across trials and motion corrected."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os, sys, time, copy\n",
    "import numpy as np\n",
    "import scipy.spatial.distance as distance\n",
    "import matplotlib.pyplot as plt\n",
    "import ipyparallel\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import caiman as cm\n",
    "from caiman.source_extraction.cnmf import cnmf as cnmf\n",
    "from caiman.source_extraction.cnmf import params as params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.environ['MKL_NUM_THREADS']='1'\n",
    "os.environ['OPENBLAS_NUM_THREADS']='1'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Input file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_folder = '/Users/Henry/Data/temp/Dendrites_Gwen/M5.2/20181211/S1/parameterTuning'\n",
    "# data_folder = '/home/luetcke/test/M5.2/20181211/S1/parameterTuning'\n",
    "# mmap_file = '20181211_S1_Join_G0_F707_P0_rig_remFrames_d1_84_d2_508_d3_1_order_C_frames_704_.mmap'\n",
    "frame_rate = 10.2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "parameters"
    ]
   },
   "outputs": [],
   "source": [
    "# this cell is tagged as `parameters`\n",
    "mmap_file = '20181211_S1_Join_G0_F707_P0_rig_remFrames_d1_84_d2_508_d3_1_order_C_frames_704_.mmap'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mmap_file = os.path.join(data_folder, mmap_file)\n",
    "\n",
    "print('\\nUsing input file %s\\n' % (mmap_file))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Compute params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ncpus = 4"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Setup cluster"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%bash -s \"$ncpus\"\n",
    "source /opt/Anaconda3-5.1.0-Linux-x86_64/bin/activate caiman || source activate caiman\n",
    "ipcluster stop\n",
    "sleep 5\n",
    "ipcluster start --daemonize -n $1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "time.sleep(5)\n",
    "# connect client\n",
    "client = ipyparallel.Client()\n",
    "time.sleep(2)\n",
    "while len(client) < ncpus:\n",
    "    sys.stdout.write(\".\")  # Give some visual feedback of things starting\n",
    "    sys.stdout.flush()     # (de-buffered)\n",
    "    time.sleep(0.5)\n",
    "\n",
    "# create dview object\n",
    "client.direct_view().execute('__a=1', block=True)\n",
    "dview = client[:]\n",
    "n_processes = len(client)\n",
    "print('\\n\\nThe cluster appears to be setup. Number of parallel processes: %d' % (n_processes))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Parameters for source extraction\n",
    "Define the important parameters for calcium source extraction."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# dataset dependent parameters\n",
    "decay_time = 0.4                            # length of a typical transient in seconds\n",
    "\n",
    "# parameters for source extraction and deconvolution\n",
    "p = 1                         # order of the autoregressive system\n",
    "gnb = 2                       # number of global background components\n",
    "merge_thresh = 0.8            # merging threshold, max correlation allowed\n",
    "rf = [7,14]                   # half-size of the patches in pixels. e.g., if rf=25, patches are 50x50\n",
    "rf = None\n",
    "stride_cnmf = 3               # amount of overlap between the patches in pixels\n",
    "K = 20                        # max. number of components per patch\n",
    "gSig = [7,35]                 # expected half size of neurons in pixels\n",
    "\n",
    "method_init = 'sparse_nmf'    # initialization method (if analyzing dendritic data use 'sparse_nmf', else 'greedy_roi')\n",
    "#alpha_snmf = 10e2            # sparsity penalty for dendritic data analysis through sparse NMF\n",
    "alpha_snmf = 1\n",
    "normalize_init = True         # default is True\n",
    "sigma_smooth_snmf = (0.5, 1, 1) # defaults to (0.5, 0.5, 0.5)\n",
    "max_iter_snmf = 500           # defaults to 500\n",
    "\n",
    "ssub = 1                      # spatial subsampling during initialization\n",
    "tsub = 1                      # temporal subsampling during intialization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create Parameters object\n",
    "# unspecified parameters get default values\n",
    "opts_dict = {'fnames': [mmap_file],\n",
    "             'fr': frame_rate,\n",
    "            'decay_time': decay_time,\n",
    "            'p': p,\n",
    "            'nb': gnb,\n",
    "            'rf': rf,\n",
    "            'K': K,\n",
    "             'gSig': gSig,\n",
    "            'stride': stride_cnmf,\n",
    "            'method_init': method_init,\n",
    "            'alpha_snmf': alpha_snmf,\n",
    "            'normalize_init': normalize_init,\n",
    "            'sigma_smooth_snmf': sigma_smooth_snmf,\n",
    "            'max_iter_snmf': max_iter_snmf,\n",
    "            'rolling_sum': True,\n",
    "            'only_init': True,\n",
    "            'ssub': ssub,\n",
    "            'tsub': tsub}\n",
    "\n",
    "opts = params.CNMFParams(params_dict=opts_dict)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Prepare data for source extraction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Yr, dims, T = cm.load_memmap(mmap_file)\n",
    "images = np.reshape(Yr.T, [T] + list(dims), order='F')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Display frame average"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(30,30))\n",
    "avg_img = np.mean(images,axis=0)\n",
    "plt.imshow(avg_img, cmap='gray'), plt.title('Frame average', fontsize=32);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "frame_ix = 100\n",
    "plt.figure(figsize=(30,30))\n",
    "plt.imshow(images[frame_ix,:,:], cmap='gray'), plt.title('Frame %d' % (frame_ix), fontsize=32);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Run CNMF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "t_start = time.time()\n",
    "\n",
    "# Extract spatial and temporal components on patches and combine them\n",
    "# for this step deconvolution is turned off (p=0)\n",
    "opts.set('temporal', {'p': 0})\n",
    "cnm = cnmf.CNMF(n_processes, params=opts, dview=dview)\n",
    "cnm.fit(images)\n",
    "     \n",
    "# Re-run seeded CNMF on accepted patches to refine and perform deconvolution\n",
    "cnm.params.set('temporal', {'p': p})\n",
    "cnm2 = cnm.refit(images, dview=dview)\n",
    "\n",
    "t_elapsed = time.time() - t_start\n",
    "print('\\nFinished Source Extract in %1.2f s' % (t_elapsed))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Evaluate components"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cnm2.dview = None\n",
    "cnm_final = copy.deepcopy(cnm2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Parameters for evaluation\n",
    "quality_params = {\n",
    "    'min_SNR': 3,               # signal to noise ratio for accepting a component\n",
    "    'rval_thr': 0.99,           # space correlation threshold for accepting a component\n",
    "    'use_cnn': False,           # use CNN classifier\n",
    "    'cnn_thr': 0.95,            # threshold for CNN based classifier\n",
    "    'cnn_lowest': 0.1           # neurons with cnn probability lower than this value are rejected\n",
    "}\n",
    "\n",
    "opts.set('quality', quality_params)\n",
    "cnm_final.estimates.evaluate_components(images, opts, dview=dview)\n",
    "print('Found %d good / %d bad components\\n' % (len(cnm_final.estimates.idx_components), \n",
    "                                               len(cnm_final.estimates.idx_components_bad)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# calculate correlation image\n",
    "cc = cm.local_correlations(images.transpose(1,2,0))\n",
    "cc[np.isnan(cc)] = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def nb_view_components(cnm_list, img, good_or_bad='good'):\n",
    "    '''\n",
    "    View components in Caiman slider plot for different planes. \n",
    "    Choose 'good' or 'bad' to display accepted or rejected components.\n",
    "    '''\n",
    "    for ix_plane, cnm in enumerate(cnm_list):\n",
    "        show_plot = True\n",
    "        print('Plane %d' % (ix_plane))\n",
    "        if good_or_bad == 'good':\n",
    "            component_list = cnm.estimates.idx_components\n",
    "        elif good_or_bad == 'bad':\n",
    "            component_list = cnm.estimates.idx_components_bad\n",
    "        \n",
    "        if len(component_list) == 0:\n",
    "            print('No valid %s components in this plane!\\n\\n' % (good_or_bad))\n",
    "            show_plot = False\n",
    "        elif len(component_list) == 1: # adress caiman bug if only 1 component\n",
    "            print('Found 1 %s component. Duplicating due to Caiman bug.' % (good_or_bad))\n",
    "            component_list = np.append(component_list, component_list[0])\n",
    "        if show_plot:\n",
    "            cnm.estimates.nb_view_components(img=img, idx=component_list)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Interactive component plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# accepted components\n",
    "# nb_view_components([cnm_final], cc, good_or_bad='good')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# rejected components\n",
    "# nb_view_components([cnm_final], cc, good_or_bad='bad')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_component_contours(cnm, images, idx_comps, data_folder, file_stem, label='good'):\n",
    "    avg_img = np.mean(images,axis=0)\n",
    "    \n",
    "    A = cnm.estimates.A\n",
    "    A_dense = A.todense()\n",
    "\n",
    "    counter = 1\n",
    "    plt.figure(figsize=(30,30));\n",
    "    for i_comp in range(len(idx_comps)):\n",
    "        plt.subplot(len(idx_comps),2,counter)\n",
    "        if counter == 1:\n",
    "            plt.title('CNMF Components', fontsize=24);\n",
    "\n",
    "        counter += 1\n",
    "        dummy = cm.utils.visualization.plot_contours(A[:,idx_comps[i_comp]], avg_img, cmap='gray', \n",
    "                                                     colors='r', display_numbers=False)\n",
    "        component_img = np.array(np.reshape(A_dense[:,idx_comps[i_comp]], avg_img.shape, order='F'))\n",
    "        plt.subplot(len(idx_comps),2,counter)\n",
    "        counter += 1\n",
    "        plt.imshow(component_img), plt.title('Component %1.0f' % (i_comp), fontsize=24)\n",
    "\n",
    "    plt.tight_layout()\n",
    "\n",
    "    out_file = '%sComponentContours_%s_test.png' % (file_stem, label)\n",
    "    fig_name = os.path.join(data_folder, out_file)\n",
    "\n",
    "    plt.savefig(fig_name)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "file_stem = os.path.basename(mmap_file).replace('.mmap','')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_component_contours(cnm_final, images, cnm_final.estimates.idx_components, data_folder, file_stem, label='good')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Component post-processing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First try to remove components consisting of many small spots spread over a large part of the field-of-view. This is done in two ways:\n",
    "1. Calculate component sparsity (i.e. the fraction of pixels with 0)\n",
    "2. The cosine distance between non-zero pixels.\n",
    "\n",
    "For good components, the sparsity should be high (i.e. > 0.99) and the distance between component pixels should be small (i.e. < 0.01)\n",
    "\n",
    "To make the distinction clearer, it helps to threshold the component map before, i.e. at 10% of the max. value."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "A = cnm_final.estimates.A\n",
    "A_dense = A.todense()\n",
    "idx_components = cnm_final.estimates.idx_components"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# component sparsity ... fraction of pixels with 0\n",
    "# distance between non-zero pixels\n",
    "thresh = 0.1 # threshold at thresh*max\n",
    "sparsity = []\n",
    "dist = []\n",
    "for ix in idx_components:\n",
    "    component_img = np.array(np.reshape(A_dense[:,ix], avg_img.shape, order='F'))\n",
    "    component_img[component_img < thresh*np.max(component_img)] = 0\n",
    "    zeros = np.where(component_img==0)\n",
    "    sparsity.append((zeros[0].shape / np.prod(avg_img.shape))[0])\n",
    "    dist.append(distance.pdist(np.nonzero(component_img), metric='cosine')[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sparsity_threshold = 0.99 # components with less sparsity will be excluded\n",
    "distance_threshold = 0.01 # components with larger average cosine distance will be excluded"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "idx_components_new = [x for (ix,x) in enumerate(idx_components) if sparsity[ix]>sparsity_threshold and dist[ix]<distance_threshold]\n",
    "idx_components_new"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_component_contours(cnm_final, images, idx_components_new, data_folder, file_stem, label='processed')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.signal import correlate2d as correlate2d"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# component cross-correlation\n",
    "for ix1 in idx_components_new:\n",
    "    for ix2 in idx_components_new:\n",
    "        if ix2 <= ix1:\n",
    "            continue\n",
    "        comp1 = np.array(np.reshape(A_dense[:,ix1], [1,np.prod(avg_img.shape)]))\n",
    "        comp2 = np.array(np.reshape(A_dense[:,ix2], [1,np.prod(avg_img.shape)]))\n",
    "        cc = np.corrcoef(comp1, comp2)[0][1]\n",
    "        print('Component %d - %d:\\t%1.3f' % (ix1,ix2,cc))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "A_good = A_dense[:,idx_components_new]\n",
    "A_good.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# PCA on spatial components\n",
    "from sklearn.decomposition import PCA\n",
    "pca = PCA(n_components=A_good.shape[1])\n",
    "pca.fit(A_good)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(np.arange(1,A_good.shape[1]+1), np.cumsum(pca.explained_variance_ratio_),'o-')\n",
    "plt.xlabel('number of components')\n",
    "plt.ylabel('cumulative explained variance');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Transform spatial components\n",
    "n_comps = 1 # number of output components\n",
    "pca = PCA(n_components=n_comps)\n",
    "pca.fit(A_good)\n",
    "A_pca = pca.transform(A_good)\n",
    "print(\"original shape:   \", A_good.shape)\n",
    "print(\"transformed shape:\", A_pca.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot PCA component(s)\n",
    "counter = 1\n",
    "plt.figure(figsize=(30,30))\n",
    "for comp in A_pca.T:\n",
    "    plt.subplot(A_pca.shape[1], 1, counter)\n",
    "    img = np.array(np.reshape(comp, avg_img.shape, order='F'))\n",
    "    plt.imshow(component_img)\n",
    "    plt.title('PCA Component %d' % (counter), fontsize=24)\n",
    "    counter += 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Stop cluster"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%bash\n",
    "source /opt/Anaconda3-5.1.0-Linux-x86_64/bin/activate caiman || source activate caiman\n",
    "ipcluster stop\n",
    "sleep 1"
   ]
  }
 ],
 "metadata": {
  "celltoolbar": "Tags",
  "kernelspec": {
   "display_name": "caiman",
   "language": "python",
   "name": "caiman"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
