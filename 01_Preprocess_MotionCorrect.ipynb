{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preprocess and motion correct movies\n",
    "Step 1 of the Caiman processing pipeline for dendritic two-photon calcium imaging movies."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Imports & Setup\n",
    "The first cells import the various Python modules required by the notebook. In particular, a number of modules are imported from the Caiman package. In addition, we also setup the environment so that everything works as expected."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Generic imports\n",
    "# from __future__ import absolute_import, division, print_function\n",
    "# from builtins import *\n",
    "from __future__ import print_function\n",
    "\n",
    "import os, sys, glob, platform, shutil\n",
    "import json\n",
    "import time, datetime\n",
    "from functools import partial\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import skimage.transform\n",
    "from scipy import interpolate\n",
    "from tifffile import imread, imsave\n",
    "from IPython.display import clear_output\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# on Linux we have to add the caiman folder to Pythonpath\n",
    "if platform.system() == 'Linux':\n",
    "    sys.path.append(os.path.expanduser('~/caiman'))\n",
    "# environment variables for parallel processing\n",
    "os.environ['MKL_NUM_THREADS']='1'\n",
    "os.environ['OPENBLAS_NUM_THREADS']='1'\n",
    "os.environ['VECLIB_MAXIMUM_THREADS']='1'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# CaImAn imports\n",
    "import caiman as cm\n",
    "from caiman.motion_correction import MotionCorrect"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Specify experimental parameters\n",
    "\n",
    "**Update!**\n",
    "\n",
    "Here we specify where the files are located, how the files are called, the frame rate of the acquisition, how to crop the movies and how many files to process.\n",
    "- data_folder ... the folder where the data is located on the volume `Data`.\n",
    "- ext ... the extension of the TIF files (e.g. .tif)\n",
    "- crop_pixel_xy ... crop movies by specified number of pixels in x and y (e.g. to remove artifacts)\n",
    "- max_sessions, max_spots, max_files ... maximum number of sessions / spots / files to process, e.g. for testing (if 0, all sessions / spots/ files will be processed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "animal_folder = 'M1_for_processing'\n",
    "date_folder = 'M1_2018-01-31'\n",
    "session_folder = 'S1'\n",
    "max_files = 50 # how many files to process per session (0 for all)\n",
    "ext = '.tif'\n",
    "frame_rate = 13.1316 # in Hz\n",
    "crop_pixel_xy = (25,0) # crop movies by specified number of pixels in x and y\n",
    "\n",
    "# create the complete path to the data folder\n",
    "if platform.system() == 'Linux':\n",
    "    data_folder = '/home/ubuntu/Data/Henry_test'\n",
    "elif platform.system() == 'Darwin':\n",
    "    data_folder = '/Users/Henry/polybox/Data_temp/Dendrites_Gwen'\n",
    "data_folder = os.path.join(data_folder, animal_folder, date_folder, session_folder)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# create list of TIF files for processing\n",
    "tiff_files = sorted([x for x in os.listdir(data_folder) if x.endswith(ext) and not x.endswith('_crop' + ext)])\n",
    "if max_files and len(tiff_files) > max_files:\n",
    "    tiff_files = tiff_files[:max_files]\n",
    "tiff_files = [os.path.join(data_folder, x) for x in tiff_files]\n",
    "print('Selected %1.0f TIF files' % len(tiff_files))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load TIF files, crop and re-save"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def cropTif(fname, crop_pixel):\n",
    "    \"\"\"\n",
    "    Crop TIF file in x and / or y. Save output as *_crop.tif. Only process movies.\n",
    "    fname ... input TIF file\n",
    "    crop_pixel ... number of pixels in x and y to crop\n",
    "    \n",
    "    returns is_movie (true/false)\n",
    "    \"\"\"\n",
    "    is_movie = True\n",
    "    # load data\n",
    "    mov = imread(fname)\n",
    "    if len(mov.shape) < 3: # not a movie!\n",
    "        is_movie = False\n",
    "#         print('%s is not a movie. Skipping.' % (fname))\n",
    "    else:\n",
    "         # crop pixels (e.g. due to artifacts at the edged)\n",
    "        mov = mov[:,crop_pixel[1]:,crop_pixel[0]:]\n",
    "        # resave as tiff\n",
    "        imsave(fname.replace('.tif','_crop.tif'), mov)\n",
    "    return is_movie"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def getFramesTif(fname):\n",
    "    \"\"\"\n",
    "    Returns the number of frames in a multi-frame TIF file.\n",
    "    Return 0 for single-page TIFs.\n",
    "    \"\"\"\n",
    "    # load data\n",
    "    mov = imread(fname)\n",
    "    if len(mov.shape) < 3: # not a movie!\n",
    "        return 0\n",
    "    else:\n",
    "        return mov.shape[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Setup cluster\n",
    "The default backend mode for parallel processing is through the multiprocessing package. This will allow us to use all the cores in the VM. Note that the `cropTif` function has to be defined before starting the cluster, so that pool workers have the function available."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# start the cluster (if a cluster already exists terminate it)\n",
    "n_processes = 8 # number of compute processes (None to select automatically)\n",
    "if 'dview' in locals():\n",
    "    dview.terminate()\n",
    "c, dview, n_processes = cm.cluster.setup_cluster(\n",
    "    backend='local', n_processes=n_processes, single_thread=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Then we call the function through the multiprocessing `map` method to make use of multiple cores."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "is_movie = dview.map(partial(cropTif, crop_pixel=crop_pixel_xy), tiff_files)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Then, create the list of cropped TIF files for motion correction, excluding files that are not movies."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tiff_files_crop = [x.replace('.tif','_crop.tif') for ix, x in enumerate(tiff_files) if is_movie[ix]]\n",
    "print('Processing %1.0f files:' % (len(tiff_files_crop)))\n",
    "print(*tiff_files_crop[:10], sep='\\n')\n",
    "if len(tiff_files_crop) > 10:\n",
    "    print('...')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Join cropped TIF files\n",
    "Next, we create a large joined TIF file from individual cropped files. Further processing will be done on the joined file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load movies\n",
    "movies = cm.load(tiff_files_crop)\n",
    "total_frames = movies.shape[0]\n",
    "dims = (movies.shape[1], movies.shape[2])\n",
    "# derive joined file name and save\n",
    "joined_tif = '%s_%s_Join_%1.0f_crop.tif' % (date_folder, session_folder, total_frames)\n",
    "imsave(os.path.join(data_folder, joined_tif), movies)\n",
    "print('Saved joined TIF file %s' % (joined_tif))\n",
    "frames_per_movie = dview.map(getFramesTif, tiff_files)\n",
    "movies = None # free the memory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create a Json file with information about source files\n",
    "meta = {\"joined_file\": joined_tif, \n",
    "        \"source_frames\": frames_per_movie, \n",
    "        \"source_file\": [x.replace(data_folder + os.path.sep,'') for x in tiff_files_crop]}\n",
    "json_fname = joined_tif.replace('.tif','.json')\n",
    "with open(os.path.join(data_folder, json_fname), 'w') as fid:\n",
    "    json.dump(meta, fid)\n",
    "print('Created JSON metadata file %s' % (json_fname))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Motion correction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First, setup the parameters for motion correction. The following parameters influence the **quality** of the motion correction:\n",
    "- niter_rig ... number of iterations for rigid registration (larger = better). Little improvement likely above 5-10.\n",
    "- strides ... intervals at which patches are laid out for motion correction (smaller = better)\n",
    "- overlaps ... overlap between patches\n",
    "\n",
    "Note that smaller values for strides / overlap will improve registration but also lead to NaNs in the output image. In general, there is a trade-off between the quality of registration and the presence / number of NaNs in the output (at least if there is significant motion)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# parameters for motion correction\n",
    "params = {'niter_rig': 5,\n",
    "          'max_shifts': (int(np.round(dims[0]/10)), int(np.round(dims[1]/10))),  # maximum allow rigid shift\n",
    "          # if none all the splits are processed and the movie is saved\n",
    "          'num_splits_to_process_rig': None,\n",
    "          # intervals at which patches are laid out for motion correction\n",
    "          'strides': (24, 24),\n",
    "          # overlap between pathes (size of patch strides+overlaps)\n",
    "          'overlaps': (24, 24),\n",
    "          # if none all the splits are processed and the movie is saved\n",
    "          'num_splits_to_process_els': [28, None],\n",
    "          'upsample_factor_grid': 4,  # upsample factor to avoid smearing when merging patches\n",
    "          # maximum deviation allowed for patch with respect to rigid shift\n",
    "          'max_deviation_rigid': 3,\n",
    "                 }"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There are also some parameters for computing the quality metrics. These probably don't have to be changed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# parameters for computing metrics\n",
    "winsize = 100\n",
    "swap_dim = False\n",
    "resize_fact_flow = 1    # downsample for computing ROF"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, we define some functions. See the function doc strings for further information."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def setupMC(fname, params):\n",
    "    \"\"\"\n",
    "    Configure motion correction oject mc with input filename and parameters.\n",
    "    \n",
    "    Return mc\n",
    "    \"\"\"\n",
    "    mov = cm.load(fname)\n",
    "    mc = MotionCorrect(fname, mov.min(), dview=dview, \n",
    "                       max_shifts=params['max_shifts'], \n",
    "                       niter_rig=params['niter_rig'], \n",
    "                       num_splits_to_process_rig=params['num_splits_to_process_rig'], \n",
    "                       strides= params['strides'], \n",
    "                       overlaps= params['overlaps'], \n",
    "                       num_splits_to_process_els=params['num_splits_to_process_els'], \n",
    "                       upsample_factor_grid=params['upsample_factor_grid'], \n",
    "                       max_deviation_rigid=params['max_deviation_rigid'], \n",
    "                       shifts_opencv = True, nonneg_movie = False)\n",
    "    return mc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def interpolateNans(frame, n=10):\n",
    "    \"\"\"\n",
    "    Interpolate NaN values in frame with average of n closest non-nan pixels\n",
    "    \n",
    "    Return interpolated frame\n",
    "    \"\"\"\n",
    "    frame_interp = frame.copy()\n",
    "    # indices for all NaN pixels\n",
    "    nan_pixel = np.array(np.where(np.isnan(frame))).T\n",
    "    if not len(nan_pixel):\n",
    "        return frame\n",
    "    # indices for all non-NaN pixels\n",
    "    valid_pixel = np.array(np.where(~np.isnan(frame))).T\n",
    "    for pix in nan_pixel:\n",
    "        # distance between NaN pixel and all valid pixels\n",
    "        dist = np.linalg.norm(valid_pixel - pix, axis=1)\n",
    "        # find the closest pixels and get their values in frame\n",
    "        closest_pixel = valid_pixel[np.argsort(dist)[:n],:]\n",
    "        closest_pixel_vals = frame[closest_pixel[:,0],closest_pixel[:,1]]\n",
    "        # replace NaN with average\n",
    "        frame_interp[pix[0],pix[1]] = np.mean(closest_pixel_vals)\n",
    "\n",
    "    return frame_interp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def computeMetrics(mc, bord_px_els, swap_dim, winsize, resize_fact_flow):\n",
    "    \"\"\"\n",
    "    Compute the quality metrics for the registration.\n",
    "    \"\"\"\n",
    "    \n",
    "    final_size = np.subtract(mc.total_template_els.shape, bord_px_els) # remove pixels in the boundaries\n",
    "    \n",
    "    tmpl_rig, corr_orig, flows_orig, norms_orig, crispness_orig = \\\n",
    "    cm.motion_correction.compute_metrics_motion_correction(mc.fname[0], final_size[0], final_size[1],\n",
    "                                                           swap_dim, winsize=winsize, play_flow=False, \n",
    "                                                           resize_fact_flow=resize_fact_flow)\n",
    "\n",
    "    tmpl_rig, corr_rig, flows_rig, norms_rig, crispness_rig = \\\n",
    "    cm.motion_correction.compute_metrics_motion_correction(mc.fname_tot_rig[0], final_size[0], final_size[1],\n",
    "                                                           swap_dim, winsize=winsize, play_flow=False, \n",
    "                                                           resize_fact_flow=resize_fact_flow)\n",
    "\n",
    "    tmpl_els, corr_els, flows_els, norms_els, crispness_els = \\\n",
    "    cm.motion_correction.compute_metrics_motion_correction(mc.fname_tot_els[0], final_size[0], final_size[1],\n",
    "                                                           swap_dim, winsize=winsize, play_flow=False, \n",
    "                                                           resize_fact_flow=resize_fact_flow)\n",
    "    \n",
    "    metrics = {\n",
    "        'tmpl_rig': tmpl_rig,\n",
    "        'corr_orig': corr_orig,\n",
    "        'flows_orig': flows_orig,\n",
    "        'crispness_orig': crispness_orig,\n",
    "        'norms_orig': norms_orig,\n",
    "        \n",
    "        'corr_rig': corr_rig,\n",
    "        'flows_rig': flows_rig,\n",
    "        'crispness_rig': crispness_rig,\n",
    "        'norms_rig': norms_rig,\n",
    "        \n",
    "        'tmpl_els': tmpl_els,\n",
    "        'corr_els': corr_els,\n",
    "        'flows_els': flows_els,\n",
    "        'crispness_els': crispness_els,\n",
    "        'norms_els': norms_els,\n",
    "    }\n",
    "    \n",
    "    return metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def removeBoundaryPixels(movie, mc):\n",
    "    \"\"\"\n",
    "    Remove the boundary pixels corresponding to the max. shift of the pw-rigid registration.\n",
    "    \"\"\"\n",
    "    # compute borders to exclude\n",
    "    bord_px_els = np.ceil(np.maximum(np.max(np.abs(mc.x_shifts_els)), \n",
    "                                     np.max(np.abs(mc.y_shifts_els)))).astype(np.int)\n",
    "    # remove pixels in the boundaries\n",
    "    final_size = np.subtract(mc.total_template_els.shape, bord_px_els)\n",
    "    final_size_x = final_size[0]\n",
    "    final_size_y = final_size[1]\n",
    "    max_shft_x = np.int(np.ceil((np.shape(mov_els)[1] - final_size_x) / 2))\n",
    "    max_shft_y = np.int(np.ceil((np.shape(mov_els)[2] - final_size_y) / 2))\n",
    "    max_shft_x_1 = - ((np.shape(mov_els)[1] - max_shft_x) - (final_size_x))\n",
    "    max_shft_y_1 = - ((np.shape(mov_els)[2] - max_shft_y) - (final_size_y))\n",
    "    if max_shft_x_1 == 0:\n",
    "        max_shft_x_1 = None\n",
    "\n",
    "    if max_shft_y_1 == 0:\n",
    "        max_shft_y_1 = None\n",
    "    \n",
    "    movie = movie[:, max_shft_x:max_shft_x_1, max_shft_y:max_shft_y_1]\n",
    "    mc.total_template_els = mc.total_template_els[max_shft_x:max_shft_x_1, max_shft_y:max_shft_y_1]\n",
    "    \n",
    "    return movie, mc"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we are ready to run motion correction for the joined TIF file. If there are a lot of concatenated trials, this might take a while to complete.\n",
    "\n",
    "The following outputs will be saved:\n",
    "- result of rigid motion correction in Python mmap format and as TIF file\n",
    "- result of pw-rigid motion correction in Python mmap format and as TIF file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "t_start = time.time()\n",
    "fname = os.path.join(data_folder, joined_tif)\n",
    "# create mc object\n",
    "mc = setupMC(fname, params)\n",
    "# compute initial template by binned median filtering\n",
    "# this template will be refined during the registration process\n",
    "template = cm.load(fname).bin_median(window=10)\n",
    "\n",
    "# apply rigid correction\n",
    "mc.motion_correct_rigid(save_movie=True, template=template)\n",
    "# apply piecewise rigid correction\n",
    "mc.motion_correct_pwrigid(save_movie=True, template=mc.total_template_rig, show_template = False)\n",
    "\n",
    "# load corrected movie - els\n",
    "mov_els = cm.load(mc.fname_tot_els[0])\n",
    "\n",
    "mov_els, mc = removeBoundaryPixels(mov_els, mc)\n",
    "\n",
    "# interpolate NaNs\n",
    "mov_els_copy = mov_els.copy()\n",
    "for ix in range(mov_els.shape[0]):\n",
    "    mov_els_copy[ix,:,:] = interpolateNans(mov_els[ix,:,:])\n",
    "\n",
    "# save pw-rigid corrected movies as TIF\n",
    "dummy_fname = 'dummy_%s.tif' % (datetime.datetime.now().strftime(\"%Y%m%d%H%M%S\"))\n",
    "dummy_fname = os.path.join(data_folder, dummy_fname)\n",
    "imsave(dummy_fname, mov_els_copy)\n",
    "\n",
    "# save pw-rigid corrected and interpolated movie as mmap\n",
    "base_name = os.path.join(data_folder, '%s_%s_Join_crop_els_' % (date_folder, session_folder))\n",
    "fname_new = cm.save_memmap([dummy_fname], base_name=base_name, order='F')\n",
    "\n",
    "# remove previous mmap file and rename TIF file\n",
    "os.remove(mc.fname_tot_els[0])\n",
    "mc.fname_tot_els = [fname_new]\n",
    "os.rename(dummy_fname, fname_new.replace('.mmap', '.tif'))\n",
    "\n",
    "# clear memory\n",
    "mov_els = None\n",
    "mov_els_copy = None\n",
    "\n",
    "# save rigid corrected movies as TIF\n",
    "imsave(mc.fname_tot_rig[0].replace('.mmap','.tif'), cm.load(mc.fname_tot_rig[0]))\n",
    "\n",
    "clear_output()\n",
    "\n",
    "# print elapsed time\n",
    "t_elapsed = time.time() - t_start\n",
    "print('\\nFinished MC in %1.2f s (%1.2f s per frame)' % (t_elapsed, t_elapsed/total_frames))\n",
    "\n",
    "if platform.system() == 'Darwin':\n",
    "    os.system('say \"your program has finished\"')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Assess quality of motion correction\n",
    "A number of key metrics can be calculated to assess how much motion correction improved overall motion. \n",
    "1. Correlation\n",
    "Correlations of each frame with the template image (binned median) for original, rigid correction and pw-rigid correction. The mean correlation gives an overall impression of motion. The minimum correlation indicates the parts of the movie that are worst affected by motion. Larger correlations indicate less motion.\n",
    "2. Crispness\n",
    "Crispness provides a measure of the smoothness of the corrected average image. Intuitively, a dataset with nonregistered motion will have a blurred mean image, resulting in a lower value for the total gradient field norm. Thus, larger values indicate a crisper average image and less residual motion. Crispness is calculated from the gradient field of the mean image (`np.gradient`).\n",
    "3. Residual optical flow\n",
    "Optic flow algorithms attempt to match each frame to the template by estimating locally smooth displacement fields. The output is an image where each pixel described the local displacement between template and frame at this point. The smaller the local displacement, the better the registration. Here we compute the matrix norm of the optic flow matrix as summary statistic."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# compute quality assessment metrics\n",
    "mtrs = computeMetrics(mc, 0, swap_dim, winsize, resize_fact_flow)\n",
    "# correlations, crispness and norms of residual optic flow as indicators of registration quality\n",
    "crispness_metric = np.array([mtrs['crispness_orig'], mtrs['crispness_rig'], mtrs['crispness_els']])\n",
    "norms_metric = np.array([np.mean(mtrs['norms_orig']), np.mean(mtrs['norms_rig']), np.mean(mtrs['norms_els'])])\n",
    "corr_mean_metric = np.array([np.mean(mtrs['corr_orig']), np.mean(mtrs['corr_rig']), np.mean(mtrs['corr_els'])])\n",
    "corr_min_metric = np.array([np.min(mtrs['corr_orig']), np.min(mtrs['corr_rig']), np.min(mtrs['corr_els'])])\n",
    "\n",
    "clear_output()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Print different metrics for raw movie and rigid / pw-rigid corrected movies."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('MC evaluation:')\n",
    "if corr_mean_metric[0] > corr_mean_metric[1] or corr_mean_metric[0] > corr_mean_metric[2]:\n",
    "    print('\\x1b[1;03;31m'+'Mean corr - raw / rigid / pw_rigid: ' \n",
    "          + str(['{:.2f}'.format(i) for i in corr_mean_metric]) + '\\x1b[0m')\n",
    "else:\n",
    "    print('Mean corr - raw / rigid / pw_rigid: ' + str(['{:.2f}'.format(i) for i in corr_mean_metric]))\n",
    "\n",
    "if corr_min_metric[0] > corr_min_metric[1] or corr_min_metric[0] > corr_min_metric[2]:\n",
    "    print('\\x1b[1;03;31m'+'Min corr - raw / rigid / pw_rigid: ' \n",
    "          + str(['{:.2f}'.format(i) for i in corr_min_metric])+ '\\x1b[0m')\n",
    "else:\n",
    "    print('Min corr - raw / rigid / pw_rigid: ' + str(['{:.2f}'.format(i) for i in corr_min_metric]))\n",
    "if crispness_metric[0] > crispness_metric[1] or crispness_metric[0] > crispness_metric[2]:\n",
    "    print('\\x1b[1;03;31m'+'Crispness - raw / rigid / pw_rigid: ' \n",
    "          + str(['{:.0f}'.format(i) for i in crispness_metric]) + '\\x1b[0m')\n",
    "else:\n",
    "    print('Crispness - raw / rigid / pw_rigid: ' + str(['{:.0f}'.format(i) for i in crispness_metric]))\n",
    "if norms_metric[0] < norms_metric[1] or norms_metric[0] < norms_metric[2]:\n",
    "    print('\\x1b[1;03;31m'+'Norms - raw / rigid / pw_rigid: ' \n",
    "          + str(['{:.0f}'.format(i) for i in norms_metric]) + '\\x1b[0m')\n",
    "else:\n",
    "    print('Norms - raw / rigid / pw_rigid: ' + str(['{:.2f}'.format(i) for i in norms_metric]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Correlation with template image\n",
    "Plot correlations of each frame with the template image (binned median) for original, rigid correction and pw-rigid correction."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create figure\n",
    "plt.figure(figsize = (20,10))\n",
    "# line plot\n",
    "plt.subplot(211); plt.plot(mtrs['corr_orig']); plt.plot(mtrs['corr_rig']); plt.plot(mtrs['corr_els'])\n",
    "plt.legend(['Original','Rigid','PW-Rigid']), plt.xlabel('Frame'), plt.ylabel('Correlation')\n",
    "axes = plt.gca(); axes.set_xlim([0,len(mtrs['corr_els'])]); axes.set_ylim([-0.1,1]);\n",
    "# scatter plot: raw vs. rigid\n",
    "plt.subplot(223); plt.scatter(mtrs['corr_orig'], mtrs['corr_rig']); plt.xlabel('Original'); \n",
    "plt.ylabel('Rigid'); plt.plot([0,1],[0,1],'r--')\n",
    "axes = plt.gca(); axes.set_xlim([0,1]); axes.set_ylim([0,1]); plt.axis('square');\n",
    "# scatter plot: rigid vs. pw-rigid\n",
    "plt.subplot(224); plt.scatter(mtrs['corr_rig'], mtrs['corr_els']); plt.xlabel('Rigid'); \n",
    "plt.ylabel('PW-Rigid'); plt.plot([0,1],[0,1],'r--')\n",
    "axes = plt.gca(); axes.set_xlim([0,1]); axes.set_ylim([0,1]); plt.axis('square');"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Residual optic flow\n",
    "Optic flow algorithms attempt to match each frame to the template by estimating locally smooth displacement fields. The output is an image where each pixel described the local displacement between template and frame at this point. The smaller the local displacement, the better the registration. Norms are the matrix norms of the optic flow matrix."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot the results of Residual Optical Flow\n",
    "metrics_files = [mc.fname_tot_els[0][:-4] + '_metrics.npz', mc.fname_tot_rig[0][:-4] +\n",
    "       '_metrics.npz', mc.fname[0][:-4] + '_metrics.npz']\n",
    "\n",
    "plt.figure(figsize = (20,10))\n",
    "for cnt, fl, metr in zip(range(len(metrics_files)),metrics_files,['pw_rigid','rigid','raw']):\n",
    "    with np.load(fl) as ld:\n",
    "        print('Correction: %s' % (metr))\n",
    "        print('Norms: %1.2f +- %1.2f' % (np.mean(ld['norms']), np.std(ld['norms'])))\n",
    "        \n",
    "        plt.subplot(len(metrics_files), 3, 1 + 3 * cnt)\n",
    "        plt.ylabel(metr)\n",
    "                   \n",
    "        if metr == 'raw':\n",
    "            mean_img = np.mean(cm.load(mc.fname[0]), axis=0)\n",
    "        elif metr == 'rigid':\n",
    "            mean_img = np.mean(cm.load(mc.fname_tot_rig[0]), axis=0)\n",
    "        elif metr == 'pw_rigid':\n",
    "            mean_img = np.mean(cm.load(mc.fname_tot_els[0]), axis=0)\n",
    "        \n",
    "        lq, hq = np.nanpercentile(mean_img, [.5, 99.5])\n",
    "        plt.imshow(mean_img, vmin=lq, vmax=hq, cmap='gray')\n",
    "        if not cnt:\n",
    "            plt.title('Mean')\n",
    "        plt.subplot(len(metrics_files), 3, 3 * cnt + 2)\n",
    "        plt.imshow(ld['img_corr'], vmin=0, vmax=.5, cmap='gray')\n",
    "        if not cnt:\n",
    "            plt.title('Correlation image')\n",
    "        plt.subplot(len(metrics_files), 3, 3 * cnt + 3)\n",
    "        flows = ld['flows']\n",
    "        plt.imshow(np.mean(np.sqrt(flows[:, :, :, 0]**2 + flows[:, :, :, 1]**2), 0), vmin=0, vmax=0.5, cmap='gray')\n",
    "        plt.colorbar()\n",
    "        if not cnt:\n",
    "            plt.title('Mean optical flow')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Detect frames with bad motion\n",
    "Identify frames with significant residual motion (low correlation with template). Write a JSON file with criterion and indices of frames matching the criterion. This file can be used in further analysis to exclude the frames corrupted by motion."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def writeJsonBadFrames(criterion, thresh, frame_ix, mc, mc_type, data_folder):\n",
    "    exclude_info = {\"criterion\": criterion, \n",
    "        \"threshold:\": thresh, \n",
    "        \"frames\": frame_ix}\n",
    "    if mc_type == 'els':\n",
    "        json_fname = mc.fname_tot_els[0].replace('.mmap','') + 'badFrames' + '.json'\n",
    "    elif mc_type == 'rig':\n",
    "        json_fname = mc.fname_tot_rig[0].replace('.mmap','') + 'badFrames' + '.json'\n",
    "    with open(os.path.join(data_folder, json_fname), 'w') as fid:\n",
    "        json.dump(exclude_info, fid)\n",
    "    print('Created JSON metadata file %s' % (json_fname))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "thresh = 0.1 # find frames where value is less than criterion\n",
    "# pw-rigid registration\n",
    "criterion = 'corr_els'\n",
    "bad_frames = [ix for ix, i in enumerate(mtrs[criterion]) if i < thresh]\n",
    "print('%1.0f frames matching criterion after pw-rigid registration.' % (len(bad_frames)))\n",
    "writeJsonBadFrames(criterion, thresh, bad_frames, mc, 'els', data_folder)\n",
    "# rigid registration\n",
    "criterion = 'corr_rig'\n",
    "bad_frames = [ix for ix, i in enumerate(mtrs[criterion]) if i < thresh]\n",
    "print('\\n%1.0f frames matching criterion after rigid registration.' % (len(bad_frames)))\n",
    "writeJsonBadFrames(criterion, thresh, bad_frames, mc, 'rig', data_folder)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Old code\n",
    "Code below is kept from previous versions of the notebook. **Do NOT use!!!**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, loop over all selected files and run motion correction. For each file, we store the `mc` object in `mc_results`. Each correction also produces 2 output files in CaImAn mmap format (one for rigid and one for elastic registration). The mmap files are stored in the same folder as the original TIFF image. Finally, different metrics are computed to assess the quality of motion correction. The metrics are stored in `*metrics.npz` files. \n",
    "\n",
    "Note that Caiman does not allow computing of metrics if the output image contains NaNs. This is called a \"failed\" registration here. But it may in fact be expected, for example if there is out-of-frame motion. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "t_start = time.time()\n",
    "mc_results = []\n",
    "bad_movies = []\n",
    "crispness_metric = np.zeros((len(tiff_files_crop),3))\n",
    "norms_metric = np.zeros((len(tiff_files_crop),3))\n",
    "corr_min_metric = np.zeros((len(tiff_files_crop),3))\n",
    "corr_mean_metric = np.zeros((len(tiff_files_crop),3))\n",
    "\n",
    "for ix, fname in enumerate(tiff_files_crop):\n",
    "    print('Running MC for %s' % (fname.replace(data_folder, '~')))\n",
    "    \n",
    "    # create mc object\n",
    "    mc = setupMC(fname, params)\n",
    "    \n",
    "    # compute initial template by binned median filtering\n",
    "    # this template will be refined during the registration process\n",
    "    template = cm.load(fname).bin_median(window=10)\n",
    "    \n",
    "    # apply rigid correction\n",
    "    mc.motion_correct_rigid(save_movie=True, template=template)\n",
    "    # apply piecewise rigid correction\n",
    "    mc.motion_correct_pwrigid(save_movie=True, template=mc.total_template_rig, show_template = False)\n",
    "\n",
    "    # append results\n",
    "    mc_results.append(mc)\n",
    "    \n",
    "    # compute borders to exclude\n",
    "    bord_px_els = np.ceil(np.maximum(np.max(np.abs(mc.x_shifts_els)), \n",
    "                                     np.max(np.abs(mc.y_shifts_els)))).astype(np.int)\n",
    "    \n",
    "    # compute metrics for the results\n",
    "    try:\n",
    "        mtrs = computeMetrics(mc, bord_px_els, swap_dim, winsize, resize_fact_flow)\n",
    "    \n",
    "        # correlations, crispness and norms of residual optic flow as indicators of registration quality\n",
    "        crispness_metric[ix,:] = np.array([mtrs['crispness_orig'], \n",
    "                                           mtrs['crispness_rig'], mtrs['crispness_els']])\n",
    "        norms_metric[ix,:] = np.array([np.mean(mtrs['norms_orig']), \n",
    "                                       np.mean(mtrs['norms_rig']), np.mean(mtrs['norms_els'])])\n",
    "        corr_mean_metric[ix,:] = np.array([np.mean(mtrs['corr_orig']), \n",
    "                                           np.mean(mtrs['corr_rig']), np.mean(mtrs['corr_els'])])\n",
    "        corr_min_metric[ix,:] = np.array([np.min(mtrs['corr_orig']), \n",
    "                                          np.min(mtrs['corr_rig']), np.min(mtrs['corr_els'])])\n",
    "    except:\n",
    "        # sometimes the metrics cannot be computed, due to NaNs in the resulting pw-rigid image\n",
    "        # this means that the registration is probably bad and / or the movie contains lots of motion\n",
    "        crispness_metric[ix,:] = np.array([np.nan, np.nan, np.nan])\n",
    "        norms_metric[ix,:] = np.array([np.nan, np.nan, np.nan])\n",
    "        corr_mean_metric[ix,:] = np.array([np.nan, np.nan, np.nan])\n",
    "        corr_min_metric[ix,:] = np.array([np.nan, np.nan, np.nan])\n",
    "        bad_movies.append(fname.replace(data_folder, '~'))\n",
    "           \n",
    "    clear_output()\n",
    "\n",
    "# print the \"failed\" registrations\n",
    "print('%1.0f Failed registrations (%1.2f %%):' % (len(bad_movies), (len(bad_movies)/len(tiff_files_crop))*100))\n",
    "print(bad_movies)\n",
    "    \n",
    "# print elapsed time\n",
    "t_elapsed = time.time() - t_start\n",
    "print('\\nFinished MC for %1.0f files in %1.2f s (%1.2f s per file)' % (len(mc_results), \n",
    "                                                                     t_elapsed, t_elapsed/len(mc_results)))\n",
    "if platform.system() == 'Darwin':\n",
    "    os.system('say \"your program has finished\"')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Assess quality of motion correction\n",
    "A number of key metrics can be calculated to assess how much motion correction improved overall motion. \n",
    "1. Correlation\n",
    "Correlations of each frame with the template image (binned median) for original, rigid correction and pw-rigid correction. The mean correlation gives an overall impression of motion. The minimum correlation indicates the parts of the movie that are worst affected by motion. Larger correlations indicate less motion.\n",
    "2. Crispness\n",
    "Crispness provides a measure of the smoothness of the corrected average image. Intuitively, a dataset with nonregistered motion will have a blurred mean image, resulting in a lower value for the total gradient field norm. Thus, larger values indicate a crisper average image and less residual motion. Crispness is calculated from the gradient field of the mean image (`np.gradient`).\n",
    "3. Residual optical flow\n",
    "Optic flow algorithms attempt to match each frame to the template by estimating locally smooth displacement fields. The output is an image where each pixel described the local displacement between template and frame at this point. The smaller the local displacement, the better the registration. Here we compute the matrix norm of the optic flow matrix as summary statistic.\n",
    "\n",
    "The cell below prints summary statistics of the different metrics for all processed files. See further below for code to generate detailed plots for individual files."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "for ix, file_metrix in enumerate(norms_metric):\n",
    "    if ix:\n",
    "        print('')\n",
    "    print('MC evaluation - %s:' % (tiff_files_crop[ix]))\n",
    "    if corr_mean_metric[ix,0] > corr_mean_metric[ix,1] or corr_mean_metric[ix,0] > corr_mean_metric[ix,2]:\n",
    "        print('\\x1b[1;03;31m'+'Mean corr - raw / rigid / pw_rigid: ' \n",
    "              + str(['{:.2f}'.format(i) for i in corr_mean_metric[ix,:]])+ '\\x1b[0m')\n",
    "    else:\n",
    "        print('Mean corr - raw / rigid / pw_rigid: ' + str(['{:.2f}'.format(i) for i in corr_mean_metric[ix,:]]))\n",
    "        \n",
    "    if corr_min_metric[ix,0] > corr_min_metric[ix,1] or corr_min_metric[ix,0] > corr_min_metric[ix,2]:\n",
    "        print('\\x1b[1;03;31m'+'Min corr - raw / rigid / pw_rigid: ' \n",
    "              + str(['{:.2f}'.format(i) for i in corr_min_metric[ix,:]])+ '\\x1b[0m')\n",
    "    else:\n",
    "        print('Min corr - raw / rigid / pw_rigid: ' + str(['{:.2f}'.format(i) for i in corr_min_metric[ix,:]]))\n",
    "    if crispness_metric[ix,0] > crispness_metric[ix,1] or crispness_metric[ix,0] > crispness_metric[ix,2]:\n",
    "        print('\\x1b[1;03;31m'+'Crispness - raw / rigid / pw_rigid: ' \n",
    "              + str(['{:.0f}'.format(i) for i in crispness_metric[ix,:]]) + '\\x1b[0m')\n",
    "    else:\n",
    "        print('Crispness - raw / rigid / pw_rigid: ' + str(['{:.0f}'.format(i) for i in crispness_metric[ix,:]]))\n",
    "    if norms_metric[ix,0] < norms_metric[ix,1] or norms_metric[ix,0] < norms_metric[ix,2]:\n",
    "        print('\\x1b[1;03;31m'+'Norms - raw / rigid / pw_rigid: ' \n",
    "              + str(['{:.0f}'.format(i) for i in norms_metric[ix,:]]) + '\\x1b[0m')\n",
    "    else:\n",
    "        print('Norms - raw / rigid / pw_rigid: ' + str(['{:.2f}'.format(i) for i in norms_metric[ix,:]]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Summary scatter plots of the above numbers. These can be useful to detect failed registrations or optimise parameters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "plt.figure(figsize = (10,20))\n",
    "# Mean correlation\n",
    "plt.subplot(421); plt.scatter(corr_mean_metric[:,0], corr_mean_metric[:,1]); plt.xlabel('Original'); \n",
    "plt.ylabel('Rigid'); plt.plot([0,1],[0,1],'r--')\n",
    "axes = plt.gca(); axes.set_xlim([0,1]); axes.set_ylim([0,1]); plt.axis('square'); plt.title('Mean Correlation')\n",
    "plt.subplot(422); plt.scatter(corr_mean_metric[:,0], corr_mean_metric[:,2]); plt.xlabel('Original'); \n",
    "plt.ylabel('PW-Rigid'); plt.plot([0,1],[0,1],'r--')\n",
    "axes = plt.gca(); axes.set_xlim([0,1]); axes.set_ylim([0,1]); plt.axis('square');\n",
    "# Min correlation\n",
    "plt.subplot(423); plt.scatter(corr_min_metric[:,0], corr_min_metric[:,1]); plt.xlabel('Original'); \n",
    "plt.ylabel('Rigid'); plt.plot([0,1],[0,1],'r--')\n",
    "axes = plt.gca(); axes.set_xlim([0,1]); axes.set_ylim([0,1]); plt.axis('square'); plt.title('Min. Correlation')\n",
    "plt.subplot(424); plt.scatter(corr_min_metric[:,0], corr_min_metric[:,2]); plt.xlabel('Original'); \n",
    "plt.ylabel('PW-Rigid'); plt.plot([0,1],[0,1],'r--')\n",
    "axes = plt.gca(); axes.set_xlim([0,1]); axes.set_ylim([0,1]); plt.axis('square');\n",
    "# Crispness\n",
    "plt.subplot(425); plt.scatter(crispness_metric[:,0], crispness_metric[:,1]); plt.xlabel('Original'); \n",
    "plt.ylabel('Rigid'); plt.plot([1000,3000],[1000,3000],'r--')\n",
    "axes = plt.gca(); axes.set_xlim([1000,3000]); axes.set_ylim([1000,3000]); plt.axis('square'); plt.title('Crispness')\n",
    "plt.subplot(426); plt.scatter(crispness_metric[:,0], crispness_metric[:,2]); plt.xlabel('Original'); \n",
    "plt.ylabel('PW-Rigid'); plt.plot([1000,3000],[1000,3000],'r--')\n",
    "axes = plt.gca(); axes.set_xlim([0,1]); axes.set_ylim([0,1]); plt.axis('square');\n",
    "# Norms\n",
    "plt.subplot(427); plt.scatter(norms_metric[:,0], norms_metric[:,1]); plt.xlabel('Original'); \n",
    "plt.ylabel('Rigid'); plt.plot([0,60],[0,60],'r--')\n",
    "axes = plt.gca(); axes.set_xlim([0,60]); axes.set_ylim([0,60]); plt.axis('square'); plt.title('ROF Norms')\n",
    "plt.subplot(428); plt.scatter(norms_metric[:,0], norms_metric[:,2]); plt.xlabel('Original'); \n",
    "plt.ylabel('PW-Rigid'); plt.plot([0,60],[0,60],'r--')\n",
    "axes = plt.gca(); axes.set_xlim([0,60]); axes.set_ylim([0,60]); plt.axis('square');"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Interactively assess quality of motion correction\n",
    "`compute_metrics_motion_correction` can be used to calculate different metrics to assess the quality of motion correction. Below, select a specific file, calculate the metrics and then inspect the results as plots / images."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# select file to assess\n",
    "file_ix = 1 # e.g. 1, 2, 3, ...\n",
    "if file_ix > len(mc_results):\n",
    "    raise Exception('MC results only available for %1.0f files!' % (len(mc_results)))\n",
    "mc = mc_results[file_ix-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "%%capture\n",
    "\n",
    "# compute borders to exclude\n",
    "bord_px_els = np.ceil(np.maximum(np.max(np.abs(mc.x_shifts_els)),\n",
    "                                 np.max(np.abs(mc.y_shifts_els)))).astype(np.int)\n",
    "    \n",
    "# compute metrics for the results\n",
    "mtrs = computeMetrics(mc, bord_px_els, swap_dim, winsize, resize_fact_flow)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Correlation with template image\n",
    "Plot correlations of each frame with the template image (binned median) for original, rigid correction and pw-rigid correction."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "plt.figure(figsize = (20,10))\n",
    "plt.subplot(211); plt.plot(mtrs['corr_orig']); plt.plot(mtrs['corr_rig']); plt.plot(mtrs['corr_els'])\n",
    "plt.legend(['Original','Rigid','PW-Rigid'])\n",
    "plt.subplot(223); plt.scatter(mtrs['corr_orig'], mtrs['corr_rig']); plt.xlabel('Original'); \n",
    "plt.ylabel('Rigid'); plt.plot([0,1],[0,1],'r--')\n",
    "axes = plt.gca(); axes.set_xlim([0,1]); axes.set_ylim([0,1]); plt.axis('square');\n",
    "plt.subplot(224); plt.scatter(mtrs['corr_rig'], mtrs['corr_els']); plt.xlabel('Rigid'); \n",
    "plt.ylabel('PW-Rigid'); plt.plot([0,1],[0,1],'r--')\n",
    "axes = plt.gca(); axes.set_xlim([0,1]); axes.set_ylim([0,1]); plt.axis('square');"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Crispness\n",
    "This provides a measure of the smoothness of the corrected average image. Intuitively, a dataset with nonregistered\n",
    "motion will have a blurred mean image, resulting in a lower value for the total gradient field norm. Thus, larger values indicate a crisper average image and less residual motion. Crispness is calculated from the gradient field of the mean image (`np.gradient`)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "print('Crispness original: %1.0f' % (mtrs['crispness_orig']))\n",
    "print('Crispness rigid: %1.0f' % (mtrs['crispness_rig']))\n",
    "print('Crispness elastic: %1.0f' % (mtrs['crispness_els']))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Residual optic flow\n",
    "Optic flow algorithms attempt to match each frame to the template by estimating locally smooth displacement fields. The output is an image where each pixel described the local displacement between template and frame at this point. The smaller the local displacement, the better the registration. Norms are the matrix norms of the optic flow matrix."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# plot the results of Residual Optical Flow\n",
    "metrics_files = [mc.fname_tot_els[0][:-4] + '_metrics.npz', mc.fname_tot_rig[0][:-4] +\n",
    "       '_metrics.npz', mc.fname[0][:-4] + '_metrics.npz']\n",
    "\n",
    "plt.figure(figsize = (20,10))\n",
    "for cnt, fl, metr in zip(range(len(metrics_files)),metrics_files,['pw_rigid','rigid','raw']):\n",
    "    with np.load(fl) as ld:\n",
    "        print('Correction: %s' % (metr))\n",
    "        print('Norms: %1.2f +- %1.2f' % (np.mean(ld['norms']), np.std(ld['norms'])))\n",
    "        \n",
    "        plt.subplot(len(metrics_files), 3, 1 + 3 * cnt)\n",
    "        plt.ylabel(metr)\n",
    "        \n",
    "        if metr == 'raw':\n",
    "            mean_img = np.mean(cm.load(mc.fname[0]), axis=0)[bord_px_els:-bord_px_els, bord_px_els:-bord_px_els]\n",
    "        elif metr == 'rigid':\n",
    "            mean_img = np.mean(cm.load(mc.fname_tot_rig[0]), axis=0)[bord_px_els:-bord_px_els, bord_px_els:-bord_px_els]\n",
    "        elif metr == 'pw_rigid':\n",
    "            mean_img = np.mean(cm.load(mc.fname_tot_els[0]), axis=0)[bord_px_els:-bord_px_els, bord_px_els:-bord_px_els]\n",
    "                    \n",
    "        lq, hq = np.nanpercentile(mean_img, [.5, 99.5])\n",
    "        plt.imshow(mean_img, vmin=lq, vmax=hq, cmap='gray')\n",
    "        if not cnt:\n",
    "            plt.title('Mean')\n",
    "        plt.subplot(len(metrics_files), 3, 3 * cnt + 2)\n",
    "        plt.imshow(ld['img_corr'], vmin=0, vmax=.5, cmap='gray')\n",
    "        if not cnt:\n",
    "            plt.title('Correlation image')\n",
    "        plt.subplot(len(metrics_files), 3, 3 * cnt + 3)\n",
    "        flows = ld['flows']\n",
    "        plt.imshow(np.mean(np.sqrt(flows[:, :, :, 0]**2 + flows[:, :, :, 1]**2), 0), vmin=0, vmax=0.5, cmap='gray')\n",
    "        plt.colorbar()\n",
    "        if not cnt:\n",
    "            plt.title('Mean optical flow')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Play movies\n",
    "Finally, concatenate the three movies and play them."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# load uncorrected and corrected movies\n",
    "mov_uc = cm.load(mc.fname)\n",
    "mov_rig = cm.load(mc.fname_tot_rig)\n",
    "mov_els = cm.load(mc.fname_tot_els)\n",
    "# compare movies\n",
    "print('Movie comparison for %s\\n(uncorrected, rigid, elastic)' % \n",
    "      (tiff_files_crop[file_ix-1]))\n",
    "mov_all = cm.concatenate([mov_uc, mov_rig, mov_els], axis=2)\n",
    "mov_all.play(fr=frame_rate, backend='notebook')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Reorganise files and delete empty files\n",
    "\n",
    "**This part is now done with a separate Matlab script.**\n",
    "\n",
    "This cell changes the folder structure from `data_folder/HH_MM_SS_Live/file_stem_ 1234.tif` to `data_folder/file_stem_1234.tif`. All the sub-folders (HH_MM_SS_Live) get deleted. The `parameters.xml` file is renamed to `file_stem_1234.xml`. This only needs to be done once. Once the files have been reorganised, running this again *should* have no effect."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# # count folders that are processed\n",
    "# processed_folders = 0\n",
    "# # loop over all items in data_folder\n",
    "# for item_1 in os.listdir(data_folder):\n",
    "#     # select only directories\n",
    "#     if os.path.isdir(os.path.join(data_folder, item_1)):\n",
    "#         # loop over all items in sub-directory\n",
    "#         for item_2 in os.listdir(os.path.join(data_folder, item_1)):\n",
    "#             # only do something if a file name starts with file_stem and ends with ext\n",
    "#             if item_2.startswith(file_stem) and item_2.endswith(ext):\n",
    "#                 # determine the trial ID (i.e. the number at the end of the TIF file)\n",
    "#                 trial_id = item_2[item_2.rfind(ext)-4:item_2.rfind(ext)]\n",
    "#                 # create the new filename (without space!)\n",
    "#                 new_file = file_stem + trial_id + ext\n",
    "#                 # rename and move the TIFF file to the top-level folder\n",
    "#                 os.rename(os.path.join(data_folder, item_1, item_2), os.path.join(data_folder, new_file))\n",
    "#                 # rename and move the XML file to the top-level folder\n",
    "#                 os.rename(os.path.join(data_folder, item_1, 'parameters.xml'), \\\n",
    "#                           os.path.join(data_folder, new_file.replace('.tif','.xml')))\n",
    "#                 # delete the subfolder\n",
    "#                 shutil.rmtree(os.path.join(data_folder, item_1))\n",
    "#                 processed_folders += 1\n",
    "# print(\"Processed %1.0f folders\" % (processed_folders))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
