{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Inspect results of motion correction\n",
    "Step 2 of the Caiman processing pipeline for multi-layer two-photon calcium imaging movies. This notebook shows the results of the motion correction performed in step 1 and allows the selection of 'bad frames' (i.e. frames which have too much residual motion). This is an interactive step that has to be run seperately for each dataset."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Specify analysis folder\n",
    "Select the folder where the results from the motion correction are stored. This folder should contain a file `caiman_mc_log.yml` with all the important information about files, parameters etc."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mc_analysis_folder = '/home/luetcke/neurophys-storage/Luetcke/Gwen/M4.3/20181114/S1'\n",
    "caiman_logfile = 'caiman_mc_log.yml'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Imports & Setup\n",
    "The first cells import the various Python modules required by the notebook. In particular, a number of modules are imported from the Caiman package. In addition, we also setup the environment so that everything works as expected."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# General imports\n",
    "import os, yaml, json, fnmatch\n",
    "from pprint import pprint\n",
    "import numpy as np\n",
    "from scipy.io import savemat\n",
    "from tifffile import imsave\n",
    "from IPython.display import clear_output\n",
    "\n",
    "# Caiman\n",
    "import caiman as cm\n",
    "import utils, mc_utils\n",
    "import caiman_utils as cm_utils\n",
    "\n",
    "# Import Bokeh library\n",
    "from bokeh.plotting import Figure, show\n",
    "from bokeh.layouts import gridplot\n",
    "from bokeh.models import Range1d, CrosshairTool, HoverTool, Legend\n",
    "from bokeh.io import output_notebook, export_svgs\n",
    "from bokeh.models.sources import ColumnDataSource\n",
    "from bokeh import palettes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This has to be in a separate cell, otherwise it wont work.\n",
    "from bokeh import resources\n",
    "output_notebook(resources=resources.INLINE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if os.path.isfile(os.path.join(mc_analysis_folder, caiman_logfile)):\n",
    "    with open(os.path.join(mc_analysis_folder, caiman_logfile)) as f:\n",
    "        mc_log = yaml.load(f, Loader=yaml.FullLoader)\n",
    "else:\n",
    "    raise Exception('Could not find %s in %s' % (caiman_logfile, mc_analysis_folder))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_folder = mc_log['data_folder']\n",
    "joined_tif_list = mc_log['joined_tif_list']\n",
    "stacked_files_by_group = mc_log['stacked_files_by_group']\n",
    "trial_indices_list = mc_log['trial_indices_list']\n",
    "total_frames_list = mc_log['total_frames_list']\n",
    "n_groups = mc_log['n_groups']\n",
    "n_planes = mc_log['n_planes']\n",
    "metrics_files = mc_log['metrics_files']\n",
    "mmap_files_rig = mc_log['mmap_files_rig']\n",
    "if mc_log['config']['mc']['pw_rigid']:\n",
    "    mmap_files_els = mc_log['mmap_files_els']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get metadata\n",
    "for file in os.listdir(data_folder):\n",
    "    if fnmatch.fnmatch(file, '%s_%s_Join_G0_*[!badFrames].json' % \n",
    "                       (mc_log['config']['data']['day_folder'], mc_log['config']['data']['area_folder'])):\n",
    "        meta = json.load(open(os.path.join(data_folder,file)))\n",
    "        break\n",
    "trial_index = np.array(meta['trial_index'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Display average signal intensity\n",
    "This step is useful as sanity check how the imported data looks like."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# select group (0, 1, ...)\n",
    "group_ix = 0\n",
    "\n",
    "# customize plot\n",
    "width = 1000\n",
    "height = 400\n",
    "\n",
    "trial_names = [x.replace(data_folder + os.path.sep,'')[:8] for x in stacked_files_by_group[group_ix]]\n",
    "\n",
    "color_map = palettes.d3['Category10'][10] # colors for different planes\n",
    "\n",
    "# prepare data structure\n",
    "trial_names = [x.replace(data_folder + os.path.sep,'')[:8] for x in stacked_files_by_group[group_ix]]\n",
    "trial_names_frames = [trial_names[x] for x in trial_indices_list[group_ix]]\n",
    "data = {'x': np.array(range(total_frames_list[group_ix])), \n",
    "        'trial_idx': trial_indices_list[group_ix],\n",
    "        'trial_name': trial_names_frames\n",
    "       }\n",
    "\n",
    "# add average for each plane\n",
    "for i_plane in range(n_planes):\n",
    "    tiff_file = os.path.join(data_folder, joined_tif_list[group_ix] + '_P%d.tif' % (i_plane))\n",
    "    mov = cm.load(tiff_file, outtype=np.int16)\n",
    "\n",
    "    # plot average signal intensity per frame\n",
    "    frame_avg = np.mean(np.mean(mov, axis=1), axis=1)\n",
    "\n",
    "    fieldname = 'y%s' % (i_plane)\n",
    "    data[fieldname] = frame_avg\n",
    "    \n",
    "data_source = ColumnDataSource(data)\n",
    "\n",
    "# create figure and plot\n",
    "p = Figure(plot_width=width, plot_height=height, title=('Frame average - Group %d' % (group_ix))) \n",
    "p.add_tools(CrosshairTool(), utils.getHover())\n",
    "for i_plane in range(n_planes):\n",
    "    p.line('x', 'y%s' % (i_plane), source=data_source, line_width=2, color=color_map[i_plane], legend='Plane %s' % (i_plane))\n",
    "\n",
    "show(p)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load metrics data\n",
    "This may take a while as the metrics file is quite large. The metrics are stored in a single list variable:\n",
    "\n",
    "`[metrics, crispness, norms, corr_mean, corr_min]`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "corr_mean = []\n",
    "corr_min = []\n",
    "crispness = []\n",
    "norms = []\n",
    "mtrs = []\n",
    "for i_group in range(n_groups):\n",
    "    mc_metrics = np.load(os.path.join(data_folder, metrics_files[i_group]))\n",
    "    corr_mean.append(mc_metrics[3])\n",
    "    corr_min.append(mc_metrics[4])\n",
    "    crispness.append(mc_metrics[1])\n",
    "    norms.append(mc_metrics[2])\n",
    "    mtrs.append(mc_metrics[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Metrics and summary plots\n",
    "Print different metrics for raw movie and rigid / pw-rigid corrected movies."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i_group in range(n_groups):\n",
    "    for i_plane in range(n_planes):\n",
    "        print('MC evaluation - Group %d - Plane %d:' % (i_group, i_plane))\n",
    "        mc_utils.printMetrics(corr_mean[i_group][i_plane], corr_min[i_group][i_plane], crispness[i_group][i_plane], norms[i_group][i_plane])\n",
    "        print('\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Plot correlations of each frame with the template image (binned median) for original, rigid correction and pw-rigid correction."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# select group (0, 1, ...)\n",
    "group_ix = 0\n",
    "# select plane (0, 1, ..)\n",
    "plane_ix = 0\n",
    "\n",
    "metrics = mtrs[group_ix]\n",
    "\n",
    "gridplot_array = []\n",
    "\n",
    "frames = np.array(range(total_frames_list[group_ix]))\n",
    "\n",
    "for plane_ix in range(n_planes):\n",
    "    gridplot_array.append([])\n",
    "    gridplot_array[plane_ix].append(Figure(plot_width=900, plot_height=300, title=('Correlation with template - Group %d - Plane %d' % (group_ix, plane_ix))))\n",
    "    gridplot_array[plane_ix][0].line(frames,np.array(metrics[plane_ix]['corr_orig']), line_width=2, legend='Original', color='blue')\n",
    "    gridplot_array[plane_ix][0].line(frames,np.array(metrics[plane_ix]['corr_rig']), line_width=2, legend='Rigid', color='orange')\n",
    "    if mc_log['config']['mc']['pw_rigid']:\n",
    "        gridplot_array[plane_ix][0].line(frames,np.array(metrics[plane_ix]['corr_els']), line_width=2, legend='PW-Rigid', color='green')\n",
    "    \n",
    "    gridplot_array[plane_ix].append(Figure(plot_width=250, plot_height=250))\n",
    "    gridplot_array[plane_ix][1].circle(np.array(metrics[plane_ix]['corr_orig']), np.array(metrics[plane_ix]['corr_rig']), size=5)\n",
    "    gridplot_array[plane_ix][1].line([0,1],[0,1], line_width=1, color='black', line_dash='dashed')\n",
    "    gridplot_array[plane_ix][1].xaxis.axis_label = 'Original'\n",
    "    gridplot_array[plane_ix][1].yaxis.axis_label = 'Rigid'\n",
    "    \n",
    "    if mc_log['config']['mc']['pw_rigid']:\n",
    "        gridplot_array[plane_ix].append(Figure(plot_width=250, plot_height=250))\n",
    "        gridplot_array[plane_ix][2].circle(np.array(metrics[plane_ix]['corr_rig']), np.array(metrics[plane_ix]['corr_els']), size=5)\n",
    "        gridplot_array[plane_ix][2].line([0,1],[0,1], line_width=1, color='black', line_dash='dashed')\n",
    "        gridplot_array[plane_ix][2].xaxis.axis_label = 'Rigid'\n",
    "        gridplot_array[plane_ix][2].yaxis.axis_label = 'PW-Rigid'\n",
    "    \n",
    "grid = gridplot(gridplot_array, sizing_mode='fixed', toolbar_location='left')\n",
    "\n",
    "show(grid)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Detect frames with bad motion\n",
    "Identify frames with significant residual motion (low correlation with template). Write a JSON file with criterion and indices of frames matching the criterion. This file can be used in further analysis to exclude the frames corrupted by motion."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "thresh = [\n",
    "    [0.07, 0.11, 0.15, 0.15]\n",
    "] # find frames where value is less than criterion (one value per group and plane)\n",
    "\n",
    "for i_group in range(n_groups):\n",
    "    metrics = mtrs[i_group]\n",
    "    for i_plane in range(n_planes):\n",
    "        print('Group %d - Plane %d' % (i_group, i_plane))\n",
    "        if mc_log['config']['mc']['pw_rigid']:\n",
    "            # pw-rigid registration\n",
    "            criterion = 'corr_els'\n",
    "            bad_frames = [ix for ix, i in enumerate(metrics[i_plane][criterion]) \n",
    "                          if i < thresh[i_group][i_plane]]\n",
    "            print('%1.0f frames matching criterion after pw-rigid registration.' % (len(bad_frames)))\n",
    "            mc_utils.writeJsonBadFrames(criterion, thresh[i_group][i_plane], \n",
    "                                        bad_frames, mc_list[i_group][i_plane], 'els', data_folder)\n",
    "        # rigid registration\n",
    "        criterion = 'corr_rig'\n",
    "        bad_frames = [ix for ix, i in enumerate(metrics[i_plane][criterion])\n",
    "                      if i < thresh[i_group][i_plane]]\n",
    "        print('\\n%1.0f frames matching criterion after rigid registration.' % (len(bad_frames)))\n",
    "        mc_utils.writeJsonBadFrames(criterion, thresh[i_group][i_plane], \n",
    "                                    bad_frames, mmap_files_rig[i_group][i_plane], 'rig', data_folder)\n",
    "        print('\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Remove bad frames"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "group_ix = 0\n",
    "\n",
    "# t_start = time.time()\n",
    "\n",
    "bad_frames = np.array([], dtype='int64')\n",
    "fname_list = []\n",
    "images_list = []\n",
    "\n",
    "# first, create list of bad frame indices (for all planes combined)\n",
    "for fname in mmap_files_rig[group_ix]:\n",
    "    bad_frames = np.concatenate((bad_frames, cm_utils.getBadFrames(os.path.join(data_folder, fname))))\n",
    "bad_frames = np.unique(bad_frames)\n",
    "\n",
    "# remove the bad frames from all files\n",
    "# trial_index = np.array((trial_indices_list[group_ix]))\n",
    "for fname in mmap_files_rig[group_ix]:\n",
    "    Yr, dims = cm_utils.loadData(os.path.join(data_folder, fname))\n",
    "    images, Y, fname_rem, bad_frames_by_trial, trial_idx = cm_utils.removeBadFrames(os.path.join(data_folder, fname), \n",
    "                                                                                      trial_index, \n",
    "                                                                                      Yr, dims, bad_frames, \n",
    "                                                                                      data_folder)\n",
    "    fname_list.append(fname_rem)\n",
    "    images_list.append(images)\n",
    "trial_index = trial_idx\n",
    "\n",
    "# t_elapsed = time.time() - t_start\n",
    "# print('Loading data / removing frames in %1.2f s' % (t_elapsed))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Export data for manual source extraction\n",
    "The following are exported to the folder where the original data is stored:\n",
    "- 1 TIFF file per plane of motion corrected images with bad frames removed\n",
    "- 1 MAT file per plane that contains:\n",
    "    - motion corrected images with bad frames removed (images)\n",
    "    - trial index for each frame (trial_index)\n",
    "    - list of trial names (trial_names)\n",
    "    - number of frames per trial (trial_frames)\n",
    "    - frame indices of bad frames (bad_frames)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bad_frames_by_trial_copy = dict()\n",
    "for key in bad_frames_by_trial.keys():\n",
    "    bad_frames_by_trial_copy['trial_%s' % (key)] = bad_frames_by_trial[key]\n",
    "\n",
    "for ix_plane, images in enumerate(images_list):\n",
    "    # export to TIFF\n",
    "    tiff_name = fname_list[ix_plane].replace('.mmap', '.tif')\n",
    "    imsave(tiff_name, images, bigtiff=True)\n",
    "    print('\\nExported TIFF file for plane %d\\n%s' % (ix_plane, tiff_name))\n",
    "    \n",
    "    # export to Matlab\n",
    "    # create dictionary for saving as mat file (field names will be variable names in Matlab)\n",
    "    mdict = {\n",
    "        'images': images,\n",
    "        'trial_index': trial_index,\n",
    "        'trial_names': meta['source_file'],\n",
    "        'trial_frames': meta['source_frames'],\n",
    "        'bad_frames': bad_frames,\n",
    "        'bad_frames_by_trial': bad_frames_by_trial_copy,\n",
    "    }\n",
    "    matfile_name = fname_list[ix_plane].replace('.mmap', '.mat')\n",
    "    savemat(matfile_name, mdict=mdict, long_field_names=True)\n",
    "    print('\\nExported MAT file for plane %d\\n%s' % (ix_plane, matfile_name))\n",
    "    \n",
    "print('Done!')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Remove temporary files\n",
    "Delete files that were created during processing and will not be required for downstream analysis. \n",
    "\n",
    "**Warning: there is no `undo` for this. Once the files have been deleted, one needs to re-run the entire motion correction pipeline in order to re-export data! Please make sure this is what you want!**\n",
    "\n",
    "The following files will be deleted:\n",
    "- all `.mmap` files\n",
    "- concatenated `.tif` files **without** bad frames removed\n",
    "- file with motion correction metrics results (`*_MC_metrics.npy`)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_files_to_delete(data_folder):\n",
    "    \"\"\"\n",
    "    Returns a list of files to delete\n",
    "    \"\"\"\n",
    "    only_files = [f for f in os.listdir(data_folder) if os.path.isfile(os.path.join(data_folder, f))]\n",
    "    files_to_delete = []\n",
    "    for file in only_files:\n",
    "        if file.endswith('_.mmap'):\n",
    "            files_to_delete.append(file)\n",
    "        elif file.endswith('_MC_metrics.npy'):\n",
    "            files_to_delete.append(file)\n",
    "        elif file.endswith('.tif') and not 'remFrames' in file:\n",
    "            files_to_delete.append(file)\n",
    "    return [os.path.join(data_folder, f) for f in files_to_delete]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_total_size(file_list):\n",
    "    \"\"\"\n",
    "    Returns the total disk space in GB for a list of files.\n",
    "    \"\"\"\n",
    "    disk_space = 0\n",
    "    for file in file_list:\n",
    "        disk_space += os.path.getsize(file)\n",
    "    return disk_space / 1000000000 # in GB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# clear any text in the output\n",
    "clear_output()\n",
    "# get the list of files to delete\n",
    "files_to_delete = get_files_to_delete(data_folder)\n",
    "\n",
    "# show files and ask to confirm\n",
    "print('The following files will be deleted and can NOT be restored:')\n",
    "pprint(files_to_delete)\n",
    "a = input(prompt=\"Type 'yes' if you are really sure: \")\n",
    "\n",
    "\n",
    "if a == 'yes':\n",
    "    print('\\nDeleting temporary files')\n",
    "    # how many GB do we save?\n",
    "    saved_disk_space = get_total_size(files_to_delete)\n",
    "    # delete\n",
    "    out = [os.remove(f) for f in files_to_delete]\n",
    "    print('\\nDone. You saved %1.1f GB disk space!' % saved_disk_space)\n",
    "else:\n",
    "    print('\\nSkipping deletion of temporary files')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "caiman",
   "language": "python",
   "name": "caiman"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
