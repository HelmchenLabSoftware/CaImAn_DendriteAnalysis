{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Run CNMF source extraction on movies\n",
    "Step 2 of the Caiman processing pipeline for dendritic two-photon calcium imaging movies. This part uses mmap files as input. These are created during motion correction with the Caiman toolbox (see `01_Preprocess_MC_3D.ipynb`). "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Imports & Setup\n",
    "The first cells import the various Python modules required by the notebook. In particular, a number of modules are imported from the Caiman package. In addition, we also setup the environment so that everything works as expected."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generic imports\n",
    "# from __future__ import absolute_import, division, print_function\n",
    "# from builtins import *\n",
    "\n",
    "import os, platform, glob, sys, re\n",
    "import fnmatch\n",
    "import json\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy.io import savemat\n",
    "\n",
    "from IPython.display import clear_output\n",
    "\n",
    "# Import Bokeh library\n",
    "import bokeh.plotting as plotting\n",
    "from bokeh.plotting import Figure, show\n",
    "from bokeh.layouts import gridplot\n",
    "from bokeh.models import Range1d, CrosshairTool, HoverTool, Legend\n",
    "from bokeh.io import output_notebook, export_svgs\n",
    "from bokeh.models.sources import ColumnDataSource\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This has to be in a separate cell, otherwise it wont work.\n",
    "from bokeh import resources\n",
    "output_notebook(resources=resources.INLINE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# on Linux we have to add the caiman folder to Pythonpath\n",
    "if platform.system() == 'Linux':\n",
    "    sys.path.append(os.path.expanduser('~/caiman'))\n",
    "# environment variables for parallel processing\n",
    "os.environ['MKL_NUM_THREADS']='1'\n",
    "os.environ['OPENBLAS_NUM_THREADS']='1'\n",
    "os.environ['VECLIB_MAXIMUM_THREADS']='1'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# CaImAn imports\n",
    "import caiman as cm\n",
    "from caiman.source_extraction.cnmf import cnmf as cnmf\n",
    "from caiman.source_extraction.cnmf import params as params\n",
    "from caiman.components_evaluation import estimate_components_quality as estimate_q\n",
    "from caiman.components_evaluation import estimate_components_quality_auto\n",
    "from caiman.utils.visualization import plot_contours, nb_view_patches, nb_plot_contour\n",
    "from caiman.source_extraction.cnmf import utilities as cnmf_utils\n",
    "import caiman_utils as cm_utils"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Select files\n",
    "The following need to be specified:\n",
    "- data_folder ... location of the data (relative to ~/Data)\n",
    "- mc_output ... select if output of rigid ('rig') or piece-wise rigid ('els') motion correction should be used (currently only 'rig' is tested and works)\n",
    "- max_files ... maximum number of files to process, e.g. for testing (if 0, all files will be processed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "animal_folder = 'M3_October_2018'\n",
    "date_folder = 'M3_2018-10-02'\n",
    "session_folder = 'S1'\n",
    "group_id = 'G0'\n",
    "\n",
    "mc_output = 'rig'\n",
    "remove_bad_frames = True # remove bad frames specified in Json file\n",
    "\n",
    "# create the complete path to the data folder\n",
    "if platform.system() == 'Linux':\n",
    "    data_folder = '/home/ubuntu/Data'\n",
    "elif platform.system() == 'Darwin':\n",
    "    data_folder = '/Users/Henry/Data/temp/Dendrites_Gwen'\n",
    "data_folder = os.path.join(data_folder, animal_folder, date_folder, session_folder)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# select the mmap file created during motion correction\n",
    "all_files = os.listdir(data_folder)\n",
    "mmap_files = sorted([x for x in all_files if x.startswith('%s_%s' % (date_folder, session_folder)) \n",
    "           and x.endswith('.mmap') and mc_output in x and group_id in x])\n",
    "n_planes = len(mmap_files)\n",
    "\n",
    "print('Found %d mmap files. Check allocation to planes!' % (n_planes))\n",
    "for i_plane in range(n_planes):\n",
    "    print('Plane %d: %s' % (i_plane, mmap_files[i_plane]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mmap_files = [os.path.join(data_folder, x) for x in mmap_files]\n",
    "# get metadata\n",
    "for file in os.listdir(data_folder):\n",
    "    if fnmatch.fnmatch(file, '%s_%s_Join_%s_*[!badFrames].json' % (date_folder, session_folder, group_id)):\n",
    "        meta = json.load(open(os.path.join(data_folder,file)))\n",
    "        break\n",
    "trial_index = np.array(meta['trial_index'])\n",
    "frame_rate = meta['frame_rate'] / n_planes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load data and remove bad frames"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fname = mmap_files[0]\n",
    "Yr, dims = cm_utils.loadData(fname)\n",
    "fname"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bad_frames, images, Y, fname_rem = cm_utils.removeBadFrames(fname, trial_index, Yr, dims, remove_bad_frames, data_folder)\n",
    "fname_rem"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Setup cluster\n",
    "The default backend mode for parallel processing is through the multiprocessing package. This will allow us to use all the cores in the VM."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# start the cluster (if a cluster already exists terminate it)\n",
    "n_processes = 8 # number of compute processes (None to select automatically)\n",
    "if 'dview' in locals() and dview is not None:\n",
    "    dview.terminate()\n",
    "c, dview, n_processes = cm.cluster.setup_cluster(\n",
    "    backend='local', n_processes=n_processes, single_thread=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# set dview to None for debugging\n",
    "if 'dview' in locals():\n",
    "    dview.terminate()\n",
    "dview = None"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Parameters for source extraction\n",
    "Next, we define the important parameters for calcium source extraction. These parameters will have to be iteratively refined for the respective datasets.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Spring 2018 Parameter (dendritic)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# parameters for source extraction and deconvolution\n",
    "# decay_time = 0.4            # length of a typical transient in seconds\n",
    "# p = 1                       # order of the autoregressive system (normally 1, 2 for fast indicators / imaging)\n",
    "# gnb = 2                     # number of global background components\n",
    "# merge_thresh = 0.8          # merging threshold, max correlation allowed\n",
    "# rf = 10                     # half-size of the patches in pixels. e.g., if rf=25, patches are 50x50 / None: no patches\n",
    "# stride_cnmf = 5             # amount of overlap between the patches in pixels\n",
    "# K = None                    # number of components per patch (usually None)\n",
    "# gSig = [4, 4]               # expected half size of neurons\n",
    "# method_init = 'sparse_nmf'  # initialization method (if analyzing dendritic data use 'sparse_nmf')\n",
    "# is_dendrites = True         # flag for analyzing dendritic data\n",
    "# #alpha_snmf = 10e2           # sparsity penalty for dendritic data analysis through sparse NMF\n",
    "# alpha_snmf = 1e-6\n",
    "\n",
    "# method_deconvolution='oasis'# deconvolution method (oasis or cvxpy)\n",
    "\n",
    "# # parameters for component evaluation\n",
    "# min_SNR = 2.5               # signal to noise ratio for accepting a component\n",
    "# rval_thr = 0.8              # space correlation threshold for accepting a component\n",
    "# use_cnn = False             # whether to use CNN to filter components\n",
    "# cnn_thr = 0.8               # threshold for CNN based classifier\n",
    "\n",
    "# final_rate = frame_rate             # final frame rate in Hz"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Autumn 2018 Parameter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# dataset dependent parameters\n",
    "decay_time = 0.4                            # length of a typical transient in seconds\n",
    "\n",
    "# parameters for source extraction and deconvolution\n",
    "p = 1                       # order of the autoregressive system\n",
    "gnb = 2                     # number of global background components\n",
    "merge_thresh = 0.8          # merging threshold, max correlation allowed\n",
    "rf = 15                     # half-size of the patches in pixels. e.g., if rf=25, patches are 50x50\n",
    "stride_cnmf = 6             # amount of overlap between the patches in pixels\n",
    "K = 4                       # number of components per patch\n",
    "gSig = [4, 4]               # expected half size of neurons in pixels\n",
    "\n",
    "method_init = 'sparse_nmf'  # initialization method (if analyzing dendritic data use 'sparse_nmf', else 'greedy_roi')\n",
    "#alpha_snmf = 10e2           # sparsity penalty for dendritic data analysis through sparse NMF\n",
    "alpha_snmf = 100\n",
    "normalize_init = True      # default is True\n",
    "\n",
    "ssub = 1                    # spatial subsampling during initialization\n",
    "tsub = 1                    # temporal subsampling during intialization\n",
    "\n",
    "# parameters for component evaluation\n",
    "min_SNR = 2.0               # signal to noise ratio for accepting a component\n",
    "rval_thr = 0.85              # space correlation threshold for accepting a component\n",
    "cnn_thr = 0.99              # threshold for CNN based classifier\n",
    "cnn_lowest = 0.1 # neurons with cnn probability lower than this value are rejected"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create Parameters object\n",
    "# unspecified parameters get default values\n",
    "opts_dict = {'fnames': fname_rem,\n",
    "            'fr': frame_rate,\n",
    "            'decay_time': decay_time,\n",
    "            'p': 1,\n",
    "            'nb': gnb,\n",
    "            'rf': rf,\n",
    "            'K': K, \n",
    "            'stride': stride_cnmf,\n",
    "            'method_init': method_init,\n",
    "            'alpha_snmf': alpha_snmf,\n",
    "             'normalize_init': normalize_init,\n",
    "            'rolling_sum': True,\n",
    "            'only_init': True,\n",
    "            'ssub': ssub,\n",
    "            'tsub': tsub,\n",
    "            'min_SNR': min_SNR,\n",
    "            'rval_thr': rval_thr,\n",
    "            'use_cnn': True,\n",
    "            'min_cnn_thr': cnn_thr,\n",
    "            'cnn_lowest': cnn_lowest}\n",
    "\n",
    "opts = params.CNMFParams(params_dict=opts_dict)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To get a dict with all parameters, use `opts.to_dict()`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Run CNMF on patches"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "opts.to_dict()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# First extract spatial and temporal components on patches and combine them\n",
    "# for this step deconvolution is turned off (p=0)\n",
    "opts.set('temporal', {'p': 0})\n",
    "cnm = cnmf.CNMF(n_processes, params=opts, dview=dview)\n",
    "cnm = cnm.fit(images)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Inspect results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot contours of found components\n",
    "Cn = cm.local_correlations(images.transpose(1,2,0))\n",
    "Cn[np.isnan(Cn)] = 0\n",
    "cnm.estimates.plot_contours_nb(img=Cn)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Re-run (seeded) CNMF on the full Field of View"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# RE-RUN seeded CNMF on accepted patches to refine and perform deconvolution \n",
    "cnm.params.set('temporal', {'p': p})\n",
    "cnm2 = cnm.refit(images, dview=dview)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Component evaluation\n",
    "the components are evaluated in three ways:\n",
    "1. the shape of each component must be correlated with the data\n",
    "2. a minimum peak SNR is required over the length of a transient\n",
    "3. each shape passes a CNN based classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cnm2.estimates.evaluate_components(images, cnm2.params, dview=dview)\n",
    "print('Found %d good / %d bad components' % (len(cnm2.estimates.idx_components), len(cnm2.estimates.idx_components_bad)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Plot contours of selected and rejected components"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cnm2.estimates.plot_contours_nb(img=Cn, idx=cnm2.estimates.idx_components)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "View traces of accepted and rejected components. Note that if you get data rate error you can start Jupyter notebooks using: 'jupyter notebook --NotebookApp.iopub_data_rate_limit=1.0e10'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# accepted components\n",
    "cnm2.estimates.nb_view_components(img=Cn, idx=cnm2.estimates.idx_components)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# rejected components\n",
    "if len(cnm2.estimates.idx_components_bad) > 0:\n",
    "    cnm2.estimates.nb_view_components(img=Cn, idx=cnm2.estimates.idx_components_bad)\n",
    "else:\n",
    "    print(\"No components were rejected.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Extract DF/F values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cnm2.estimates.detrend_df_f(quantileMin=8, frames_window=250)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Select only high quality components."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cnm2.estimates.select_components(use_object=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cnm2.estimates.nb_view_components(img=Cn, denoised_color='red')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "caiman",
   "language": "python",
   "name": "caiman"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
