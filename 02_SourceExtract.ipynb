{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Run CNMF source extraction on movies\n",
    "Step 2 of the Caiman processing pipeline for dendritic two-photon calcium imaging movies. This part uses mmap files as input. These are created during motion correction with the Caiman toolbox (see `01_Preprocess_MotionCorrect.ipynb`). "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Imports & Setup\n",
    "The first cells import the various Python modules required by the notebook. In particular, a number of modules are imported from the Caiman package. In addition, we also setup the environment so that everything works as expected."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Generic imports\n",
    "# from __future__ import absolute_import, division, print_function\n",
    "# from builtins import *\n",
    "\n",
    "import os, platform, glob, sys, re\n",
    "import json\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy.io import savemat\n",
    "\n",
    "from IPython.display import clear_output\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# on Linux we have to add the caiman folder to Pythonpath\n",
    "if platform.system() == 'Linux':\n",
    "    sys.path.append(os.path.expanduser('~/caiman'))\n",
    "# environment variables for parallel processing\n",
    "os.environ['MKL_NUM_THREADS']='1'\n",
    "os.environ['OPENBLAS_NUM_THREADS']='1'\n",
    "os.environ['VECLIB_MAXIMUM_THREADS']='1'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# CaImAn imports\n",
    "import caiman as cm\n",
    "from caiman.source_extraction.cnmf import cnmf as cnmf\n",
    "from caiman.components_evaluation import estimate_components_quality as estimate_q\n",
    "from caiman.utils.visualization import plot_contours, nb_view_patches, nb_plot_contour\n",
    "from caiman.source_extraction.cnmf import utilities as cnmf_utils"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Select files and parameters\n",
    "The following need to be specified:\n",
    "- data_folder ... location of the data (relative to ~/Data)\n",
    "- mc_output ... select if output of rigid ('rig') or piece-wise rigid ('els') motion correction should be used (currently only 'rig' is tested and works)\n",
    "- max_files ... maximum number of files to process, e.g. for testing (if 0, all files will be processed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "animal_folder = 'M1_for_processing'\n",
    "date_folder = 'M1_2018-01-31'\n",
    "spot_folder = 'S1'\n",
    "\n",
    "mc_output = 'rig'\n",
    "remove_bad_frames = True # remove bad frames specified in Json file\n",
    "\n",
    "# create the complete path to the data folder\n",
    "if platform.system() == 'Linux':\n",
    "    data_folder = '/home/ubuntu/Data/Henry_test'\n",
    "elif platform.system() == 'Darwin':\n",
    "    data_folder = '/Users/Henry/polybox/Data_temp/Dendrites_Gwen'\n",
    "data_folder = os.path.join(data_folder, animal_folder, date_folder, spot_folder)\n",
    "data_folder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# select the mmap file created during motion correction\n",
    "all_files = os.listdir(data_folder)\n",
    "matches = [x for x in all_files if x.startswith('%s_%s' % (date_folder, spot_folder)) \n",
    "           and x.endswith('.mmap') and mc_output in x]\n",
    "\n",
    "if len(matches) == 1: # if only 1 file matches, select it\n",
    "    fname = matches[0]\n",
    "    print('Selected file: %s' % (fname))\n",
    "elif len(matches) > 0: # if several files match, ask which one to choos\n",
    "    print('Found several matching files!')\n",
    "    for ix, match in enumerate(matches):\n",
    "        print('%1.0f: %s' % (ix+1,match))\n",
    "    select = raw_input('Please select your file (1-%1.0f):' % (ix+1))\n",
    "    fname = matches[int(select)-1]\n",
    "    print('Selected file: %s' % (fname))\n",
    "else: # if no file matches, throw an error\n",
    "    raise Exception('Did not find a matching mmap file!')\n",
    "\n",
    "fname = os.path.join(data_folder, fname)\n",
    "\n",
    "# get metadata for corresponding joined file\n",
    "meta = json.load(open(fname[:fname.find('_crop_')+5] + '.json'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Setup cluster\n",
    "The default backend mode for parallel processing is through the multiprocessing package. This will allow us to use all the cores in the VM."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# start the cluster (if a cluster already exists terminate it)\n",
    "n_processes = 8 # number of compute processes (None to select automatically)\n",
    "if 'dview' in locals():\n",
    "    dview.terminate()\n",
    "c, dview, n_processes = cm.cluster.setup_cluster(\n",
    "    backend='local', n_processes=n_processes, single_thread=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Parameters for source extraction\n",
    "Next, we define the important parameters for calcium source extraction. These parameters will have to be iteratively refined for the respective datasets.\n",
    "\n",
    "The parameters are stored in the Python dictionary `params_cnmf`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# parameters for source extraction and deconvolution\n",
    "p = 1                       # order of the autoregressive system (normally 1, 2 for fast indicators / imaging)\n",
    "gnb = 2                     # number of global background components\n",
    "merge_thresh = 0.8          # merging threshold, max correlation allowed\n",
    "rf = None                   # half-size of the patches in pixels. e.g., if rf=25, patches are 50x50 / None: no patches\n",
    "stride_cnmf = 6             # amount of overlap between the patches in pixels\n",
    "K = 20                      # number of components per patch\n",
    "gSig = [4, 4]               # expected half size of neurons\n",
    "init_method = 'sparse_nmf'  # initialization method (if analyzing dendritic data using 'sparse_nmf')\n",
    "is_dendrites = True         # flag for analyzing dendritic data\n",
    "#alpha_snmf = 10e2           # sparsity penalty for dendritic data analysis through sparse NMF\n",
    "alpha_snmf = 1e-6\n",
    "\n",
    "method_deconvolution='oasis'# deconvolution method (oasis or cvxpy)\n",
    "final_rate = 13.1316             # final frame rate in Hz\n",
    "\n",
    "\n",
    "# parameters for component evaluation\n",
    "# min_SNR = 2.5               # signal to noise ratio for accepting a component\n",
    "# rval_thr = 0.8              # space correlation threshold for accepting a component\n",
    "# cnn_thr = 0.8               # threshold for CNN based classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# store parameters in Python dictionary\n",
    "params = dict()\n",
    "params['p'] = p\n",
    "params['gnb'] = gnb\n",
    "params['merge_thresh'] = merge_thresh\n",
    "params['rf'] = rf\n",
    "params['stride_cnmf'] = stride_cnmf\n",
    "params['K'] = K\n",
    "params['gSig'] = gSig\n",
    "params['init_method'] = init_method\n",
    "params['is_dendrites'] = is_dendrites\n",
    "params['alpha_snmf'] = alpha_snmf\n",
    "\n",
    "params['method_deconvolution'] = method_deconvolution\n",
    "params['final_rate'] = final_rate\n",
    "\n",
    "params"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Run CNMF on joined mmap file\n",
    "According to the Caiman tutorials, CNMF source extraction should be run in several stages. First, we run CNMF on patches of the dataset and then evaluate the quality of the extracted components. Next, CNMF is run again but on the full field-of-view. Finally, the extracted components are again evaluated and classified (good and bad)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load mmap file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "Yr, dims, T = cm.load_memmap(fname)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# remove bad frames specified in corresponding Json file\n",
    "# Todo: print deleted frames\n",
    "if remove_bad_frames:\n",
    "    bad_frames = json.load(open(fname.replace('.mmap','badFrames.json')))\n",
    "    bad_frames = np.array(bad_frames['frames'])\n",
    "    Yr = np.delete(Yr, bad_frames, axis=1)\n",
    "    T = Yr.shape[1]\n",
    "    images = np.reshape(Yr.T, [T] + list(dims), order='F')\n",
    "    fname_new = cm.save_memmap([images], base_name=os.path.join(data_folder, 'removedFrames'))\n",
    "    Yr, dims, T = cm.load_memmap(fname_new)\n",
    "    print('Deleted %1d frames. Saved to new file %s.' % (len(bad_frames), os.path.basename(fname_new)))\n",
    "    print('Deleted frames:')\n",
    "    print(bad_frames)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "d1, d2 = dims\n",
    "images = np.reshape(Yr.T, [T] + list(dims), order='F')\n",
    "Y = np.reshape(Yr, dims + (T,), order='F')\n",
    "m_images = cm.movie(images)\n",
    "#  checks on movies (might take time if large!)\n",
    "if np.min(images) < 0:\n",
    "    raise Exception('Movie too negative, add_to_movie should be larger')\n",
    "if np.sum(np.isnan(images)) > 0:\n",
    "    raise Exception('Movie contains nan! You did not remove enough borders')\n",
    "# correlation image\n",
    "Cn = cm.local_correlations(Y)\n",
    "Cn[np.isnan(Cn)] = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# sanity check the image\n",
    "avg_img = np.mean(images,axis=0)\n",
    "plt.figure(figsize=(10,20))\n",
    "plt.subplot(1,2,1)\n",
    "plt.imshow(avg_img, cmap='gray'), plt.title('Frame average')\n",
    "plt.subplot(1,2,2)\n",
    "plt.imshow(Cn, cmap='jet'), plt.title('Correlation image')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Run single CNMF on full FoV, without patches"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Configure CNMF and fit to the data\n",
    "cnmf_single = cnmf.CNMF(n_processes, k=params['K'], gSig=params['gSig'], merge_thresh=params['merge_thresh'], \n",
    "                p=params['p'], dview=dview, Ain=None, gnb=params['gnb'], rf=params['rf'],\n",
    "                memory_fact=1, method_init=params['init_method'], alpha_snmf=params['alpha_snmf'],\n",
    "                method_deconvolution=params['method_deconvolution'])\n",
    "cnmf_single = cnmf_single.fit(images)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Unravel results\n",
    "A, C, b, f, YrA, sn = cnmf_single.A, cnmf_single.C, cnmf_single.b, cnmf_single.f, cnmf_single.YrA, cnmf_single.sn\n",
    "# A   ... n_pixel x n_components sparse matrix (component locations)\n",
    "# C   ... n_component x t np.array (fitted signal)\n",
    "# b   ... ? np.array\n",
    "# f   ... ? np.array (b / f related to global background components)\n",
    "# YrA ... n_component x t np.array (residual)\n",
    "# sn  ... n_pixel np.array (SNR?)\n",
    "\n",
    "print('Detected components: %1.0f' % (C.shape[0]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Evaluate components (discard low quality components)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "r_values_min = .65         # threshold on space consistency\n",
    "fitness_min = -100        # threshold on time variability\n",
    "fitness_delta_min = -100  # threshold on time variability (if nonsparse activity)\n",
    "Npeaks = 100\n",
    "thresh_C = 0.3\n",
    "Athresh = 0.1\n",
    "\n",
    "traces = C + YrA\n",
    "idx_comps, idx_comps_bad, fitness_raw, fitness_delta, r_values = estimate_q(traces, Y, A, C, b, f, final_frate=params['final_rate'], \n",
    "                                      Npeaks=Npeaks, r_values_min=r_values_min, fitness_min=fitness_min, \n",
    "                                      fitness_delta_min=fitness_delta_min, thresh_C=thresh_C, Athresh=Athresh,\n",
    "                                      return_all=True)\n",
    "print('Good / bad components: %1.0f / %1.0f' % (len(idx_comps), len(idx_comps_bad)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Plot good and bad components\n",
    "plt.figure(figsize=(20,30));\n",
    "plt.subplot(121); crd_good = cm.utils.visualization.plot_contours(A[:,idx_comps], Cn, thr=.8, vmax=0.75)\n",
    "plt.title('Contour plots of accepted components')\n",
    "plt.subplot(122); crd_bad = cm.utils.visualization.plot_contours(A[:,idx_comps_bad], Cn, thr=.8, vmax=0.75)\n",
    "plt.title('Contour plots of rejected components')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Plot good components on background image and as component map\n",
    "A_dense = A.todense()\n",
    "counter = 1\n",
    "plt.figure(figsize=(20,20));\n",
    "for i_comp in range(len(idx_comps)):\n",
    "    plt.subplot(len(idx_comps),2,counter)\n",
    "    counter += 1\n",
    "    dummy = cm.utils.visualization.plot_contours(A[:,idx_comps[i_comp]], avg_img, cmap='gray', \n",
    "                                                 colors='r', display_numbers=False)\n",
    "    component_img = np.array(np.reshape(A_dense[:,idx_comps[i_comp]], dims, order='F'))\n",
    "    plt.subplot(len(idx_comps),2,counter)\n",
    "    counter += 1\n",
    "    plt.imshow(component_img), plt.title('Component %1.0f' % (i_comp))\n",
    "    \n",
    "    if i_comp == 0:\n",
    "        component_matrix = component_img\n",
    "    else:\n",
    "        component_matrix = np.dstack((component_matrix, component_img))\n",
    "plt.tight_layout()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Save and view results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# saving\n",
    "np.savez(os.path.join(os.path.split(fname_new)[0],\n",
    "                      os.path.split(fname_new)[1][:-5] + 'results_CNMF.npz'),\n",
    "         Cn=Cn, A=A.todense(), C=C,\n",
    "         b=b, f=f, YrA=YrA, sn=sn, d1=d1, d2=d2,\n",
    "         idx_components=idx_comps, idx_components_bad=idx_comps_bad)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Interactive viewer for traces of accepted and rejected components\n",
    "**Currently does not work remotely!**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# accepted components\n",
    "if len(idx_comps) > 0:\n",
    "    nb_view_patches(Yr, A.tocsc()[:, idx_comps], C[idx_comps], \n",
    "                    b, f, dims[0], dims[1], YrA=YrA[idx_comps], image_neurons = Cn,\n",
    "                    denoised_color = 'red');\n",
    "else:\n",
    "    print(\"No accepted components!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Calculate DFF and plot traces\n",
    "The CaImAn function `detrend_df_f` uses a sliding window percentile filter to determine the baseline and compute DFF. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "F_dff = cnmf_utils.detrend_df_f(A, b, C, f, YrA = YrA, quantileMin=8, frames_window=100)\n",
    "# select good components\n",
    "F_dff = F_dff[idx_comps,:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# zoom on time axis\n",
    "# set either one to -1 for full range\n",
    "t1 = -1 # in s\n",
    "t2 = -1\n",
    "\n",
    "fig = plt.figure(figsize=(20,10)) # increase figsize to (20,10) to improve visibility\n",
    "# loop over good components to plot their respective DFF timeseries\n",
    "t = np.arange(0, F_dff.shape[-1]) / params['final_rate']\n",
    "\n",
    "if t1 > 0 and t2 > 0:\n",
    "    t1_frame = np.where(t>=t1)[0][0]\n",
    "    t2_frame = np.where(t<=t2)[0][-1]\n",
    "    t = t[t1_frame:t2_frame]\n",
    "    F_dff_plot = F_dff[:,t1_frame:t2_frame]\n",
    "else:\n",
    "    F_dff_plot = F_dff.copy()\n",
    "\n",
    "offset = 0\n",
    "for i_comp in range(len(idx_comps)):\n",
    "    plot_trace = F_dff_plot[i_comp, :]\n",
    "    plot_trace = plot_trace - min(plot_trace) + offset\n",
    "    offset = max(plot_trace)\n",
    "    plt.plot(t, plot_trace)\n",
    "\n",
    "# some improvements to the default figure\n",
    "plt.xlabel('Time [s]', fontsize=18)\n",
    "plt.ylabel('DFF', fontsize=18)\n",
    "plt.ylim((0, offset)), plt.xlim((np.min(t), np.max(t)))\n",
    "plt.title('%s %s CNMF Results' % (date_folder, spot_folder), fontsize=20)\n",
    "plt.legend(['Component %1d' % (x) for x in range(len(idx_comps))])\n",
    "ax = fig.gca()\n",
    "plt.setp(ax.get_xticklabels(), fontsize=16)\n",
    "plt.setp(ax.get_yticklabels(), fontsize=16)\n",
    "\n",
    "# save the figure if required\n",
    "# (extension determines file type)\n",
    "if t1 > 0 and t2 > 0:\n",
    "    figfile_name = '%s_%s_CNMF_results_%1d-%1ds.png' % (date_folder, spot_folder, t1, t2)\n",
    "else:\n",
    "    figfile_name = '%s_%s_CNMF_results.png' % (date_folder, spot_folder)\n",
    "plt.savefig(os.path.join(data_folder, figfile_name))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Split up by trials and save as .mat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# split up F_dff by trials\n",
    "# Todo: correct source_frames: key\n",
    "source_files = meta['source_file']\n",
    "source_frames = np.array(meta['source_frames'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# check if our numbers match\n",
    "if not (np.sum(source_frames)-len(bad_frames)) == F_dff.shape[-1]:\n",
    "    raise Exception('Sum of source frames minus number of bad frames must be equal to number of timepoints.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "results_dff = dict()\n",
    "removed_frames = dict()\n",
    "bad_frames_removed = []\n",
    "start_frame = 0\n",
    "for ix, trial_file in enumerate(source_files):\n",
    "    trial_indices = list(range(start_frame, source_frames[ix] + start_frame))\n",
    "#     print(trial_file)\n",
    "#     print('Start / stop: %1.0f / %1.0f' % (trial_indices[0], trial_indices[-1]))\n",
    "    \n",
    "    # check if trial contains bad frames (that have not been removed yet)\n",
    "    bad = [x for x in bad_frames if x in trial_indices and x not in bad_frames_removed]\n",
    "    \n",
    "    # remove indices of bad frames\n",
    "    if len(bad) > 0:\n",
    "#         print('Found %1.0f bad frames' % (len(bad)))\n",
    "        del trial_indices[-len(bad):]\n",
    "#         print('Removed frames (relative to trial start):')\n",
    "        for i_bad in bad:\n",
    "            bad_frames_removed.append(i_bad)\n",
    "        removed_frames_trial = [x-trial_indices[0] for x in bad]\n",
    "    else:\n",
    "        removed_frames_trial = []\n",
    "    \n",
    "#     print('Start / stop: %1.0f / %1.0f\\n' % (trial_indices[0], trial_indices[-1]))\n",
    "    \n",
    "    # create a valid Matlab variable / field name\n",
    "    field_name = str('x' + source_files[ix]).replace('.tif','').replace('-','_')\n",
    "    results_dff[field_name] = F_dff[:,trial_indices]\n",
    "    removed_frames[field_name] = removed_frames_trial\n",
    "    \n",
    "    start_frame = trial_indices[-1] + 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# prepare the dictionary for saving as mat file\n",
    "# the field names will be the variable names in Matlab\n",
    "mdict={'trials': [str(x) for x in source_files], \n",
    "       'dff_trial': results_dff, \n",
    "       'removed_frames': removed_frames,\n",
    "       'mean_image': avg_img,\n",
    "       'spatial_components': component_matrix\n",
    "      }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# save the .mat file\n",
    "matfile_name = '%s_%s_CNMF_results.mat' % (date_folder, spot_folder)\n",
    "savemat(os.path.join(data_folder, matfile_name), mdict=mdict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Run double CNMF first on patches, then on full FoV\n",
    "This is the recommended approach according to the tutorial notebooks."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# for this step deconvolution is turned off (p=0)\n",
    "cnmf_patch = cnmf.CNMF(n_processes, k=params['K'], gSig=params['gSig'], merge_thresh=params['merge_thresh'], \n",
    "                p=0, dview=dview, Ain=None, rf=params['rf'], stride=params['stride_cnmf'], \n",
    "                memory_fact=1, method_init=params['init_method'], alpha_snmf=params['alpha_snmf'],\n",
    "                only_init_patch=True, gnb=params['gnb'], method_deconvolution=params['method_deconvolution'])\n",
    "cnmf_patch = cnmf_patch.fit(images)\n",
    "\n",
    "A_tot, C_tot, YrA_tot, b_tot, f_tot, sn_tot = \\\n",
    "cnmf_patch.A, cnmf_patch.C, cnmf_patch.YrA, cnmf_patch.b, cnmf_patch.f, cnmf_patch.sn\n",
    "\n",
    "#clear_output()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Evaluate components (discard low quality components)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "r_values_min = .7          # threshold on space consistency\n",
    "fitness_min = -40          # threshold on time variability\n",
    "fitness_delta_min = -40    # threshold on time variability (if nonsparse activity)\n",
    "Npeaks = 100\n",
    "traces = C_tot + YrA_tot\n",
    "idx_comps, idx_comps_bad = estimate_q(traces, Y, A_tot, C_tot, b_tot, f_tot, final_frate=params['final_rate'], \n",
    "                                      Npeaks=Npeaks, r_values_min=r_values_min, fitness_min=fitness_min, \n",
    "                                      fitness_delta_min=fitness_delta_min)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Plot contours of selected and rejected components"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Plot components\n",
    "plt.figure(figsize=(10,20));\n",
    "plt.subplot(121); crd_good = cm.utils.visualization.plot_contours(A_tot[:,idx_comps], Cn, thr=.8, vmax=0.75)\n",
    "plt.title('Contour plots of accepted components')\n",
    "plt.subplot(122); crd_bad = cm.utils.visualization.plot_contours(A_tot[:,idx_comps_bad], Cn, thr=.8, vmax=0.75)\n",
    "plt.title('Contour plots of rejected components')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Run CNMF on full field of view."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "cnmf_full = cnmf.CNMF(n_processes, k=A_tot.shape[-1], gSig=params['gSig'], merge_thresh=params['merge_thresh'], \n",
    "                p=params['p'], dview=dview, Ain=A_tot, Cin=C_tot, f_in=f_tot, rf=params['rf'],\n",
    "                memory_fact=1, method_init=params['init_method'], alpha_snmf=params['alpha_snmf'],\n",
    "                stride=params['stride_cnmf'], method_deconvolution=params['method_deconvolution'])\n",
    "cnmf_full = cnmf_full.fit(images)\n",
    "A, C, b, f, YrA, sn = cnmf_full.A, cnmf_full.C, cnmf_full.b, cnmf_full.f, cnmf_full.YrA, cnmf_full.sn\n",
    "\n",
    "#clear_output()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Recheck quality of components with stricter criteria."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "r_values_min = .7         # threshold on space consistency\n",
    "fitness_min = -100        # threshold on time variability\n",
    "fitness_delta_min = -100  # threshold on time variability (if nonsparse activity)\n",
    "Npeaks = 100\n",
    "thresh_C = 0.3\n",
    "Athresh = 0.1\n",
    "\n",
    "traces = C + YrA\n",
    "idx_comps, idx_comps_bad = estimate_q(traces, Y, A, C, b, f, final_frate=params['final_rate'], \n",
    "                                      Npeaks=Npeaks, r_values_min=r_values_min, fitness_min=fitness_min, \n",
    "                                      fitness_delta_min=fitness_delta_min, thresh_C=thresh_C, Athresh=Athresh)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Plot contours of selected and rejected components"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Plot components\n",
    "plt.figure(figsize=(10,20));\n",
    "plt.subplot(121); crd_good = cm.utils.visualization.plot_contours(A[:,idx_comps], Cn, thr=.8, vmax=0.75)\n",
    "plt.title('Contour plots of accepted components')\n",
    "plt.subplot(122); crd_bad = cm.utils.visualization.plot_contours(A[:,idx_comps_bad], Cn, thr=.8, vmax=0.75)\n",
    "plt.title('Contour plots of rejected components')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Stop cluster and clean up log files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "cm.stop_server(dview=dview)\n",
    "log_files = glob.glob('*_LOG_*')\n",
    "for log_file in log_files:\n",
    "    os.remove(log_file)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Save and view results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# saving\n",
    "np.savez(os.path.join(os.path.split(fname)[0],\n",
    "                      os.path.split(fname)[1][:-4] + 'results_CNMF.npz'),\n",
    "         Cn=Cn, A=A.todense(), C=C,\n",
    "         b=b, f=f, YrA=YrA, sn=sn, d1=d1, d2=d2,\n",
    "         idx_components=idx_comps, idx_components_bad=idx_comps_bad)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Interactive viewer for traces of accepted and rejected components\n",
    "**Currently does not work remotely!**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# accepted components\n",
    "if len(idx_comps) > 0:\n",
    "    nb_view_patches(Yr, cnmf_obj2.A.tocsc()[:, idx_comps], cnmf_obj2.C[idx_comps], \n",
    "                    cnmf_obj2.b, cnmf_obj2.f, dims[0], dims[1], YrA=cnmf_obj2.YrA[idx_comps], image_neurons = Cn,\n",
    "                    denoised_color = 'red');\n",
    "else:\n",
    "    print(\"No accepted components!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# rejected components\n",
    "if len(idx_comps_bad) > 0:\n",
    "    nb_view_patches(Yr, cnmf_obj2.A.tocsc()[:, idx_comps_bad], cnmf_obj2.C[idx_comps_bad], \n",
    "                    cnmf_obj2.b, cnmf_obj2.f, dims[0], dims[1], YrA=cnmf_obj2.YrA[idx_comps_bad], image_neurons = Cn,\n",
    "                    denoised_color = 'red');\n",
    "else:\n",
    "    print(\"No rejected components!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Reconstruct denoised movie."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "denoised = cm.movie(cnmf_obj2.A.dot(cnmf_obj2.C) + \\\n",
    "                    cnmf_obj2.b.dot(cnmf_obj2.f)).reshape(dims + (-1,), order='F').transpose([2, 0, 1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Play original and denoised data side-by-side."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "m_orig = cm.load(fname_new)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# play along side original data\n",
    "cm.concatenate([m_orig, denoised], axis=2).play(fr=params['final_rate'], \n",
    "                                                gain=15, magnification=2, offset=0, backend='notebook')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Old code\n",
    "Code below is kept from previous versions of the notebook. **Do NOT use!!!**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# create list of folders for processing\n",
    "experiment_folders = []\n",
    "session = []\n",
    "spot = []\n",
    "for session_folder in os.listdir(data_folder):\n",
    "    if os.path.isdir(os.path.join(data_folder, session_folder)):\n",
    "        if re.match(r'(\\S{2})_(\\d{4})-(\\d{2})-(\\d{2})', session_folder):\n",
    "            spot_counter = 0\n",
    "            for spot_folder in os.listdir(os.path.join(data_folder, session_folder)):\n",
    "                if os.path.isdir(os.path.join(data_folder, session_folder, spot_folder)) \\\n",
    "                and re.match(r'S[1-9]', spot_folder):\n",
    "                    experiment_folders.append(os.path.join(data_folder, session_folder, spot_folder))\n",
    "                    session.append(session_folder)\n",
    "                    spot.append(spot_folder)\n",
    "        else:\n",
    "            print('Skipping %s' % (os.path.join(data_folder, session_folder)))\n",
    "experiment_folders"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create joined mmap file from single experiments\n",
    "Next, we join individual experiments into a big mmap file. Calcium source extraction will be run on the joined mmap file. The joined mmap file (`Join_*.mmap`) is saved in the data folder together with a metadata file (`Join_*.json`) which has information about the contained experiments."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "if len(mmap_files)>1:\n",
    "    fname_new = cm.save_memmap_join(mmap_files, base_name='Join', n_chunks=12, dview=dview)\n",
    "    # move the file to the enclosing folder\n",
    "    clear_output()\n",
    "    print('\\nCreated joined mmap file\\n%s' % (fname_new))\n",
    "    # create a Json file with information about source files\n",
    "    meta = {\"joined\": fname_new, \"source\": mmap_files}\n",
    "    json_fname = fname_new.replace('.mmap','.json')\n",
    "    with open(json_fname, 'w') as fid:\n",
    "        json.dump(meta, fid)\n",
    "    print('\\nCreated meta file\\n%s' % (json_fname))\n",
    "else:\n",
    "    print('One file only, not re-saving!')\n",
    "    fname_new = mmap_files[0]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
