{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Motion correction of Dendritic GCaMP6 data with CaImAn toolbox"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Generic imports\n",
    "from __future__ import absolute_import, division, print_function\n",
    "from builtins import *\n",
    "\n",
    "import os, sys, glob, platform\n",
    "import re\n",
    "import time\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from IPython.display import clear_output\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# on Linux we need to set some environment variables\n",
    "if platform.system() == 'Linux':\n",
    "    sys.path.append(os.path.expanduser('~/caiman'))\n",
    "    os.environ['MKL_NUM_THREADS']='1'\n",
    "    os.environ['OPENBLAS_NUM_THREADS']='1'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# CaImAn imports\n",
    "import caiman as cm\n",
    "from caiman.motion_correction import tile_and_correct, motion_correction_piecewise\n",
    "from caiman.motion_correction import motion_correct_batch_rigid, motion_correct_batch_pwrigid\n",
    "from caiman.motion_correction import MotionCorrect\n",
    "from caiman.mmapping import save_memmap_each\n",
    "\n",
    "# Custom imports from utils\n",
    "from utils import define_params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "data_folder = '/home/ubuntu/example_data/M2_2018-01-30/S2'\n",
    "data_folder = '/Users/Henry/polybox/Data_temp/Dendrites_Gwen/M2_2018-01-30/S2'\n",
    "exp_id = '11-33-48_Live'\n",
    "file_id = 'test_A1_Ch0_ 0171.tif'\n",
    "frame_rate = 13.1316 # in Hz\n",
    "del_frame = 0\n",
    "\n",
    "# max_files = 5 # limit for testing (np.inf for all)\n",
    "\n",
    "path_to_images = os.path.join(data_folder, exp_id, file_id)\n",
    "\n",
    "# In this case, there is only one channel per movie. So we can just create a list of the TIFF files to import.\n",
    "tiff_files = [path_to_images]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# define parameters\n",
    "params = define_params.get_params_movie(mode='dendrite')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'K': 4,\n",
       " 'alpha_snmf': None,\n",
       " 'final_frate': 10,\n",
       " 'gSig': [4, 4],\n",
       " 'init_method': 'sparse_nmf',\n",
       " 'is_dendrites': True,\n",
       " 'max_deviation_rigid': 3,\n",
       " 'max_shifts': (8, 4),\n",
       " 'merge_thresh': 0.8,\n",
       " 'niter_rig': 1,\n",
       " 'num_splits_to_process_els': [28, None],\n",
       " 'num_splits_to_process_rig': None,\n",
       " 'overlaps': (24, 24),\n",
       " 'p': 1,\n",
       " 'rf': 15,\n",
       " 'splits_els': 10,\n",
       " 'splits_rig': 10,\n",
       " 'stride_cnmf': 6,\n",
       " 'strides': (48, 48),\n",
       " 'upsample_factor_grid': 4}"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# print parameters\n",
    "params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# get parameters from dictionary\n",
    "niter_rig = params_movie['niter_rig']\n",
    "# maximum allow rigid shift\n",
    "max_shifts = params_movie['max_shifts']\n",
    "# for parallelization split the movies in  num_splits chuncks across time\n",
    "splits_rig = params_movie['splits_rig']\n",
    "# if none all the splits are processed and the movie is saved\n",
    "num_splits_to_process_rig = params_movie['num_splits_to_process_rig']\n",
    "# intervals at which patches are laid out for motion correction\n",
    "strides = params_movie['strides']\n",
    "# overlap between pathes (size of patch strides+overlaps)\n",
    "overlaps = params_movie['overlaps']\n",
    "# for parallelization split the movies in  num_splits chuncks across time\n",
    "splits_els = params_movie['splits_els']\n",
    "# if none all the splits are processed and the movie is saved\n",
    "num_splits_to_process_els = params_movie['num_splits_to_process_els']\n",
    "# upsample factor to avoid smearing when merging patches\n",
    "upsample_factor_grid = params_movie['upsample_factor_grid']\n",
    "# maximum deviation allowed for patch with respect to rigid\n",
    "# shift\n",
    "max_deviation_rigid = params_movie['max_deviation_rigid']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# cluster params\n",
    "cluster_backend = 'local'\n",
    "# cluster_backend = 'local'\n",
    "cluster_processes = 1\n",
    "cluster_single_thread = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# display params\n",
    "display_backend = 'notebook'\n",
    "display_fr = frame_rate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# load movies and play video\n",
    "m_orig = cm.load_movie_chain(tiff_files)\n",
    "m_orig.play(fr=display_fr, backend='notebook')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Start the cluster"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "print('Starting cluster')\n",
    "c, dview, n_processes = cm.cluster.setup_cluster(\n",
    "    backend=cluster_backend, n_processes=cluster_processes, single_thread=cluster_single_thread)\n",
    "print('done')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Process motion correction for all files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def setupMC(fname, params):\n",
    "    mov = cm.load(fname)\n",
    "    mc = MotionCorrect(fname, mov.min(), dview=None, \n",
    "                       max_shifts=params['max_shifts'], \n",
    "                       niter_rig=params['niter_rig'], \n",
    "                       splits_rig=params['splits_rig'], \n",
    "                       num_splits_to_process_rig=params['num_splits_to_process_rig'], \n",
    "                       strides= params['strides'], \n",
    "                       overlaps= params['overlaps'], \n",
    "                       splits_els=params['splits_els'], \n",
    "                       num_splits_to_process_els=params['num_splits_to_process_els'], \n",
    "                       upsample_factor_grid=params['upsample_factor_grid'], \n",
    "                       max_deviation_rigid=params['max_deviation_rigid'], \n",
    "                       shifts_opencv = True, nonneg_movie = False)\n",
    "    return mc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# this loop runs the MC for each file and stores the resulting object in mc_results\n",
    "# each MC also produces 2 output files in CaImAn mmap format (one for rigid and one for elastic registration)\n",
    "# the mmap files are stored in the same folder as the original TIFF image\n",
    "t_start = time.time()\n",
    "mc_results = []\n",
    "for fname in tiff_files:\n",
    "    print('Running MC for %s' % (fname))\n",
    "    mc = setupMC(fname, params)\n",
    "    # run rigid motion correction for initial alignment\n",
    "    mc.motion_correct_rigid(save_movie=False)\n",
    "    # run piecewise rigid (elastic) correction for fine alignment (use template from rigid)\n",
    "    mc.motion_correct_pwrigid(save_movie=True, template=mc.total_template_rig, show_template = False)\n",
    "    # MEMORY MAPPING\n",
    "    # memory map the file in order 'C'\n",
    "    fname_els = mc.fname_tot_els\n",
    "    bord_px_els = np.ceil(np.maximum(np.max(np.abs(mc.x_shifts_els)),\n",
    "                                     np.max(np.abs(mc.y_shifts_els)))).astype(np.int) \n",
    "    \n",
    "    base_name = os.path.basename(fname).replace('.tif','') + '_els_'\n",
    "    fname_new = cm.save_memmap(fname_els, base_name=base_name, order = 'C', \n",
    "                               border_to_0 = bord_px_els, remove_init=del_frame)\n",
    "    os.remove(mc.fname_tot_els[0])\n",
    "    mc.fname_tot_els = fname_new\n",
    "    mc_results.append(mc)\n",
    "\n",
    "# clear output and print elapsed time\n",
    "clear_output()\n",
    "t_elapsed = time.time() - t_start\n",
    "print('Finished MC for %1.0f files in %1.2f s (%1.2f s per file)' % (len(mc_results), \n",
    "                                                                     t_elapsed, t_elapsed/len(mc_results)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# STOP CLUSTER and clean up log files\n",
    "print('Stopping cluster')\n",
    "cm.stop_server()\n",
    "\n",
    "print('Clean up log files')\n",
    "log_files = glob.glob('*_LOG_*')\n",
    "for log_file in log_files:\n",
    "    os.remove(log_file)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Results of motion correction\n",
    "`compute_metrics_motion_correction` can be used to calculate different metrics to assess the quality of motion correction."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def computeMetric(mc):\n",
    "    # compute metrics for the motion correction\n",
    "    # note that we use a modified version of cm.motion_correction.compute_metrics_motion_correction \n",
    "    # that returns frame-by-template and frame-by-frame-1 correlations\n",
    "    \n",
    "    # compute borders to exclude\n",
    "    bord_px_els = np.ceil(np.maximum(np.max(np.abs(mc.x_shifts_els)),\n",
    "                                     np.max(np.abs(mc.y_shifts_els)))).astype(np.int)\n",
    "    \n",
    "    final_size = np.subtract(mc.total_template_els.shape, 2 * bord_px_els)\n",
    "    winsize = 100\n",
    "    swap_dim = False\n",
    "    resize_fact_flow = .2\n",
    "    \n",
    "    # uncorrected\n",
    "    tmpl, corr_tmpl_unc, corr_frame_unc, flows_orig, norms, smoothness = \\\n",
    "    cm.motion_correction.compute_metrics_motion_correction(mc.fname, final_size[0], final_size[1], \n",
    "                                                           swap_dim, winsize=winsize, play_flow=False, \n",
    "                                                           resize_fact_flow=resize_fact_flow)\n",
    "    # rigid\n",
    "    tmpl, corr_tmpl_rig, corr_frame_rig, flows_orig, norms, smoothness = \\\n",
    "    cm.motion_correction.compute_metrics_motion_correction(mc.fname_tot_rig, final_size[0], final_size[1], \n",
    "                                                           swap_dim, winsize=winsize, play_flow=False, \n",
    "                                                           resize_fact_flow=resize_fact_flow)\n",
    "    # elastic\n",
    "    tmpl, corr_tmpl_els, corr_frame_els, flows_orig, norms, smoothness = \\\n",
    "    cm.motion_correction.compute_metrics_motion_correction(mc.fname_tot_els, final_size[0], final_size[1], \n",
    "                                                           swap_dim, winsize=winsize, play_flow=False, \n",
    "                                                           resize_fact_flow=resize_fact_flow)\n",
    "\n",
    "    return corr_tmpl_unc, corr_frame_unc, corr_tmpl_els, corr_frame_els"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Compare movies for selected file\n",
    "file_ix = 1 # which file to show the comparison for\n",
    "if file_ix > len(mc_results):\n",
    "    raise Exception('MC results only available for %1.0f files!' % (len(mc_results)))\n",
    "\n",
    "# load uncorrected and corrected movies\n",
    "mov_uc = cm.load(mc_results[file_ix-1].fname)[del_frame:,:,:]\n",
    "# mov_rig = cm.load(mc_results[file_ix-1].fname_tot_rig)\n",
    "mov_els = cm.load(mc_results[file_ix-1].fname_tot_els)\n",
    "# compare movies\n",
    "print('Movie comparison for %s\\n(uncorrected, elastic)' % \n",
    "      (tiff_files[file_ix-1]))\n",
    "mov_all = cm.concatenate([mov_uc, mov_els], axis=2)\n",
    "mov_all.play(fr=display_fr, backend=display_backend, magnification=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
